import os
import time
import csv
import hashlib
import gc
import psutil
import shutil
import tempfile
import gzip
import json
import signal
import threading
from datetime import datetime
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from openpyxl import load_workbook

# =========== User Config ============
SCAN_ALL_MODE = True

# üöÄ ÂÑ™ÂåñÈÅ∏È†Ö
USE_LOCAL_CACHE = True
ENABLE_FAST_MODE = True
CACHE_FOLDER = r".\\excel_cache"

# üîß Ë®∫Êñ∑ÂíåÊÅ¢Âæ©ÈÅ∏È†Ö
ENABLE_TIMEOUT = True          # ÂïüÁî®Ë∂ÖÊôÇ‰øùË≠∑
FILE_TIMEOUT_SECONDS = 120     # ÊØèÂÄãÊ™îÊ°àÊúÄÂ§ßËôïÁêÜÊôÇÈñì (Áßí)
ENABLE_MEMORY_MONITOR = True   # ÂïüÁî®Ë®òÊÜ∂È´îÁõ£Êéß
MEMORY_LIMIT_MB = 2048         # Ë®òÊÜ∂È´îÈôêÂà∂ (MB)
ENABLE_RESUME = True           # ÂïüÁî®Êñ∑ÈªûÁ∫åÂÇ≥
RESUME_LOG_FILE = r".\\baseline_progress.log"  # ÈÄ≤Â∫¶Ë®òÈåÑÊ™î

WATCH_FOLDERS = [
    r"\\network_drive\\your_folder1",
    r"\\network_drive\\your_folder2"
]

MANUAL_BASELINE_TARGET = [
    r"\\network_drive\\your_folder1\\somefile.xlsx",
    r"\\network_drive\\your_folder2\\subfolder"
]

LOG_FOLDER = r".\\excel_watch_log"
LOG_FILE_DATE = datetime.now().strftime('%Y%m%d')
CSV_LOG_FILE = os.path.join(LOG_FOLDER, f"excel_change_log_{LOG_FILE_DATE}.csv.gz")
SUPPORTED_EXTS = ('.xlsx', '.xlsm')

MAX_RETRY = 10
RETRY_INTERVAL_SEC = 2
USE_TEMP_COPY = True

WHITELIST_USERS = ['ckcm0210', 'yourwhiteuser']
LOG_WHITELIST_USER_CHANGE = True

FORCE_BASELINE_ON_FIRST_SEEN = [
    r"\\network_drive\\your_folder1\\must_first_baseline.xlsx",
    "force_this_file.xlsx"
]
# =========== End User Config ============

# ÂÖ®Â±ÄËÆäÊï∏
current_processing_file = None
processing_start_time = None
force_stop = False

def signal_handler(signum, frame):
    """ËôïÁêÜ Ctrl+C ‰∏≠Êñ∑"""
    global force_stop
    force_stop = True
    print("\nüõë Êî∂Âà∞‰∏≠Êñ∑‰ø°ËôüÔºåÊ≠£Âú®ÂÆâÂÖ®ÂÅúÊ≠¢...")
    if current_processing_file:
        print(f"   ÁõÆÂâçËôïÁêÜÊ™îÊ°à: {current_processing_file}")

signal.signal(signal.SIGINT, signal_handler)

def get_memory_usage():
    """Áç≤ÂèñÁõÆÂâçË®òÊÜ∂È´î‰ΩøÁî®Èáè"""
    try:
        process = psutil.Process(os.getpid())
        return process.memory_info().rss / 1024 / 1024  # MB
    except Exception:
        return 0

def check_memory_limit():
    """Ê™¢Êü•Ë®òÊÜ∂È´îÊòØÂê¶Ë∂ÖÈôê"""
    if not ENABLE_MEMORY_MONITOR:
        return False
    
    current_memory = get_memory_usage()
    if current_memory > MEMORY_LIMIT_MB:
        print(f"‚ö†Ô∏è Ë®òÊÜ∂È´î‰ΩøÁî®ÈáèÈÅéÈ´ò: {current_memory:.1f} MB > {MEMORY_LIMIT_MB} MB")
        print("   Ê≠£Âú®Âü∑Ë°åÂûÉÂúæÂõûÊî∂...")
        gc.collect()
        new_memory = get_memory_usage()
        print(f"   ÂûÉÂúæÂõûÊî∂Âæå: {new_memory:.1f} MB")
        return new_memory > MEMORY_LIMIT_MB
    return False

def save_progress(completed_files, total_files):
    """ÂÑ≤Â≠òÈÄ≤Â∫¶Âà∞Ê™îÊ°à"""
    if not ENABLE_RESUME:
        return
    
    try:
        progress_data = {
            "timestamp": datetime.now().isoformat(),
            "completed": completed_files,
            "total": total_files,
            "completed_list": completed_files  # ÂèØ‰ª•ÊîπÁÇ∫Ê™îÊ°àÂàóË°®
        }
        
        with open(RESUME_LOG_FILE, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, ensure_ascii=False, indent=2)
            
    except Exception as e:
        print(f"[WARN] ÁÑ°Ê≥ïÂÑ≤Â≠òÈÄ≤Â∫¶: {e}")

def load_progress():
    """ËºâÂÖ•‰πãÂâçÁöÑÈÄ≤Â∫¶"""
    if not ENABLE_RESUME or not os.path.exists(RESUME_LOG_FILE):
        return None
    
    try:
        with open(RESUME_LOG_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"[WARN] ÁÑ°Ê≥ïËºâÂÖ•ÈÄ≤Â∫¶: {e}")
        return None

def timeout_handler():
    """Ë∂ÖÊôÇËôïÁêÜÂáΩÊï∏"""
    global current_processing_file, processing_start_time, force_stop
    
    while not force_stop:
        time.sleep(10)  # ÊØè 10 ÁßíÊ™¢Êü•‰∏ÄÊ¨°
        
        if current_processing_file and processing_start_time:
            elapsed = time.time() - processing_start_time
            if elapsed > FILE_TIMEOUT_SECONDS:
                print(f"\n‚è∞ Ê™îÊ°àËôïÁêÜË∂ÖÊôÇ!")
                print(f"   Ê™îÊ°à: {current_processing_file}")
                print(f"   Â∑≤ËôïÁêÜÊôÇÈñì: {elapsed:.1f} Áßí > {FILE_TIMEOUT_SECONDS} Áßí")
                print(f"   Â∞áË∑≥ÈÅéÊ≠§Ê™îÊ°à‰∏¶ÁπºÁ∫å...")
                # ÈÄôË£°ÂèØ‰ª•Ë®≠ÁΩÆ‰∏ÄÂÄãÊ®ôË™å‰æÜË∑≥ÈÅéÁï∂ÂâçÊ™îÊ°à
                current_processing_file = None
                processing_start_time = None

def get_all_excel_files(folders):
    all_files = []
    for folder in folders:
        if os.path.isfile(folder):
            if folder.lower().endswith(SUPPORTED_EXTS) and not os.path.basename(folder).startswith('~$'):
                all_files.append(folder)
        elif os.path.isdir(folder):
            for dirpath, _, filenames in os.walk(folder):
                for f in filenames:
                    if f.lower().endswith(SUPPORTED_EXTS) and not f.startswith('~$'):
                        all_files.append(os.path.join(dirpath, f))
    return all_files

def serialize_cell_value(value):
    """Âø´ÈÄüÂ∫èÂàóÂåñ"""
    if value is None:
        return None
    elif isinstance(value, datetime):
        return value.isoformat()
    elif isinstance(value, (int, float, str, bool)):
        return value
    else:
        return str(value)

def get_excel_last_author(path):
    try:
        wb = load_workbook(path, read_only=True)
        author = wb.properties.lastModifiedBy
        wb.close()
        return author
    except Exception:
        return None

def copy_to_cache(network_path):
    """üöÄ Â∏∂Ë®∫Êñ∑ÁöÑÁ∑©Â≠òÂäüËÉΩ"""
    if not USE_LOCAL_CACHE:
        return network_path
    
    try:
        os.makedirs(CACHE_FOLDER, exist_ok=True)
        
        # Ê™¢Êü•ÂéüÂßãÊ™îÊ°àÊòØÂê¶Â≠òÂú®ÂíåÂèØËÆÄ
        if not os.path.exists(network_path):
            raise FileNotFoundError(f"Á∂≤Áµ°Ê™îÊ°à‰∏çÂ≠òÂú®: {network_path}")
        
        if not os.access(network_path, os.R_OK):
            raise PermissionError(f"ÁÑ°Ê≥ïËÆÄÂèñÁ∂≤Áµ°Ê™îÊ°à: {network_path}")
        
        file_hash = hashlib.md5(network_path.encode('utf-8')).hexdigest()[:16]
        cache_file = os.path.join(CACHE_FOLDER, f"{file_hash}_{os.path.basename(network_path)}")
        
        # Ê™¢Êü•Á∑©Â≠ò
        if os.path.exists(cache_file):
            try:
                network_mtime = os.path.getmtime(network_path)
                cache_mtime = os.path.getmtime(cache_file)
                if cache_mtime >= network_mtime:
                    return cache_file
            except Exception:
                pass
        
        # Ë§áË£ΩÊ™îÊ°àÔºåÈ°ØÁ§∫ÈÄ≤Â∫¶
        network_size = os.path.getsize(network_path)
        print(f"   üì• Ë§áË£ΩÂà∞Á∑©Â≠ò: {os.path.basename(network_path)} ({network_size/(1024*1024):.1f} MB)")
        
        copy_start = time.time()
        shutil.copy2(network_path, cache_file)
        copy_time = time.time() - copy_start
        
        print(f"      Ë§áË£ΩÂÆåÊàêÔºåËÄóÊôÇ {copy_time:.1f} Áßí")
        return cache_file
        
    except Exception as e:
        print(f"   ‚ùå Á∑©Â≠òÂ§±Êïó: {e}")
        return network_path

def dump_excel_cells_with_timeout(path):
    """üöÄ Â∏∂Ë∂ÖÊôÇ‰øùË≠∑ÁöÑ Excel ËÆÄÂèñ"""
    global current_processing_file, processing_start_time
    
    current_processing_file = path
    processing_start_time = time.time()
    
    try:
        # Ê™¢Êü•Ê™îÊ°àÂü∫Êú¨Ë≥áË®ä
        file_size = os.path.getsize(path)
        print(f"   üìä Ê™îÊ°àÂ§ßÂ∞è: {file_size/(1024*1024):.1f} MB")
        
        # ‰ΩøÁî®Êú¨Âú∞Á∑©Â≠ò
        local_path = copy_to_cache(path)
        
        if ENABLE_FAST_MODE:
            # Âø´ÈÄüÊ®°Âºè
            print(f"   üöÄ ‰ΩøÁî®Âø´ÈÄüÊ®°ÂºèËÆÄÂèñ...")
            wb = load_workbook(local_path, read_only=True, data_only=False)
            result = {}
            
            worksheet_count = len(wb.worksheets)
            print(f"   üìã Â∑•‰ΩúË°®Êï∏Èáè: {worksheet_count}")
            
            for idx, ws in enumerate(wb.worksheets, 1):
                print(f"      ËôïÁêÜÂ∑•‰ΩúË°® {idx}/{worksheet_count}: {ws.title}")
                
                ws_data = {}
                cell_count = 0
                
                if ws.max_row > 1 or ws.max_column > 1:
                    for row in ws.iter_rows(min_row=1, max_row=ws.max_row, 
                                          min_col=1, max_col=ws.max_column):
                        for cell in row:
                            if cell.value is not None:
                                formula = None
                                if cell.data_type == "f":
                                    formula = str(cell.value)
                                    if not formula.startswith("="):
                                        formula = "=" + formula
                                
                                ws_data[cell.coordinate] = {
                                    "formula": formula,
                                    "value": serialize_cell_value(cell.value)
                                }
                                cell_count += 1
                
                print(f"         ÊâæÂà∞ {cell_count} ÂÄãÊúâË≥áÊñôÁöÑ cell")
                
                if ws_data:
                    result[ws.title] = ws_data
            
            wb.close()
            print(f"   ‚úÖ Excel ËÆÄÂèñÂÆåÊàê")
        else:
            # Ê®ôÊ∫ñÊ®°Âºè
            print(f"   üìö ‰ΩøÁî®Ê®ôÊ∫ñÊ®°ÂºèËÆÄÂèñ...")
            wb_formula = load_workbook(local_path, data_only=False)
            wb_value = load_workbook(local_path, data_only=True)
            result = {}
            
            for ws_formula, ws_value in zip(wb_formula.worksheets, wb_value.worksheets):
                ws_data = {}
                for row_formula, row_value in zip(ws_formula.iter_rows(), ws_value.iter_rows()):
                    for cell_formula, cell_value in zip(row_formula, row_value):
                        try:
                            formula = cell_formula.value if cell_formula.data_type == "f" else None
                            value = serialize_cell_value(cell_value.value)
                            
                            if formula or (value not in [None, ""]):
                                if formula is not None:
                                    formula = str(formula)
                                    if not formula.startswith("="):
                                        formula = "=" + formula
                                    if not formula.startswith("'="):
                                        formula = "'" + formula
                                ws_data[cell_formula.coordinate] = {
                                    "formula": formula,
                                    "value": value
                                }
                        except Exception:
                            pass
                
                if ws_data:
                    result[ws_formula.title] = ws_data
            
            wb_formula.close()
            wb_value.close()
        
        current_processing_file = None
        processing_start_time = None
        return result
        
    except Exception as e:
        current_processing_file = None
        processing_start_time = None
        print(f"   ‚ùå Excel ËÆÄÂèñÂ§±Êïó: {e}")
        return {}

def hash_excel_content(cells_dict):
    try:
        content_str = json.dumps(cells_dict, sort_keys=True, ensure_ascii=False)
        return hashlib.md5(content_str.encode('utf-8')).hexdigest()
    except Exception:
        return None

def baseline_file_path(base_name):
    return os.path.join(LOG_FOLDER, f"{base_name}.baseline.json.gz")

def save_baseline(baseline_file, data):
    try:
        with gzip.open(baseline_file, 'wt', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, separators=(',', ':'))
    except Exception as e:
        print(f"[ERROR][save_baseline] error saving {baseline_file}: {e}")

def is_force_baseline_file(filepath):
    try:
        lowerfile = filepath.lower()
        for pattern in FORCE_BASELINE_ON_FIRST_SEEN:
            if pattern.lower() in lowerfile:
                return True
        return False
    except Exception:
        return False

def human_readable_size(num_bytes):
    for unit in ['B','KB','MB','GB','TB']:
        if num_bytes < 1024.0:
            return f"{num_bytes:,.2f} {unit}"
        num_bytes /= 1024.0
    return f"{num_bytes:.2f} PB"

def create_baseline_for_files_robust(xlsx_files, skip_force_baseline=True):
    """üõ°Ô∏è Âº∑ÂåñÁâà baseline Âª∫Á´ãÔºåÂ∏∂Ë®∫Êñ∑ÂíåÊÅ¢Âæ©ÂäüËÉΩ"""
    global force_stop
    
    total = len(xlsx_files)
    if total == 0:
        print("[INFO] Ê≤íÊúâÈúÄË¶Å baseline ÁöÑÊ™îÊ°à„ÄÇ")
        return

    print()
    print("=" * 90)
    print(" BASELINE Âª∫Á´ãÁ®ãÂ∫è (Âº∑ÂåñË®∫Êñ∑ÁâàÊú¨) ".center(90, "="))
    print("=" * 90)
    
    # Ê™¢Êü•ÊòØÂê¶Êúâ‰πãÂâçÁöÑÈÄ≤Â∫¶
    progress = load_progress()
    start_index = 0
    if progress and ENABLE_RESUME:
        print(f"üîÑ ÁôºÁèæ‰πãÂâçÁöÑÈÄ≤Â∫¶Ë®òÈåÑ:")
        print(f"   ‰πãÂâçÂÆåÊàê: {progress['completed']}/{progress['total']}")
        print(f"   Ë®òÈåÑÊôÇÈñì: {progress['timestamp']}")
        
        resume = input("ÊòØÂê¶Ë¶ÅÂæû‰∏äÊ¨°‰∏≠Êñ∑ÁöÑÂú∞ÊñπÁπºÁ∫å? (y/n): ").strip().lower()
        if resume == 'y':
            start_index = progress['completed']
            print(f"   ‚úÖ ÂæûÁ¨¨ {start_index + 1} ÂÄãÊ™îÊ°àÈñãÂßã")
    
    # ÂïüÂãïË∂ÖÊôÇÁõ£ÊéßÁ∑öÁ®ã
    if ENABLE_TIMEOUT:
        timeout_thread = threading.Thread(target=timeout_handler, daemon=True)
        timeout_thread.start()
        print(f"‚è∞ ÂïüÁî®Ë∂ÖÊôÇ‰øùË≠∑: {FILE_TIMEOUT_SECONDS} Áßí")
    
    if ENABLE_MEMORY_MONITOR:
        print(f"üíæ ÂïüÁî®Ë®òÊÜ∂È´îÁõ£Êéß: {MEMORY_LIMIT_MB} MB")
    
    optimizations = []
    if USE_LOCAL_CACHE:
        optimizations.append("Êú¨Âú∞Á∑©Â≠ò")
    if ENABLE_FAST_MODE:
        optimizations.append("Âø´ÈÄüÊ®°Âºè")
    
    print(f"üöÄ ÂïüÁî®ÂÑ™Âåñ: {', '.join(optimizations)}")
    print(f"üìÇ Baseline ÂÑ≤Â≠ò‰ΩçÁΩÆ: {os.path.abspath(LOG_FOLDER)}")
    if USE_LOCAL_CACHE:
        print(f"üíæ Êú¨Âú∞Á∑©Â≠ò‰ΩçÁΩÆ: {os.path.abspath(CACHE_FOLDER)}")
    print(f"üìã Ë¶ÅËôïÁêÜÁöÑÊ™îÊ°à: {total} ÂÄã Excel (ÂæûÁ¨¨ {start_index + 1} ÂÄãÈñãÂßã)")
    print(f"‚è∞ ÈñãÂßãÊôÇÈñì: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    print("-" * 90)
    
    # Á¢∫‰øùË≥áÊñôÂ§æÂ≠òÂú®
    os.makedirs(LOG_FOLDER, exist_ok=True)
    if USE_LOCAL_CACHE:
        os.makedirs(CACHE_FOLDER, exist_ok=True)
    
    baseline_total_size = 0
    success_count = 0
    skip_count = 0
    error_count = 0
    start_time = time.time()
    
    for i in range(start_index, total):
        if force_stop:
            print("\nüõë Êî∂Âà∞ÂÅúÊ≠¢‰ø°ËôüÔºåÊ≠£Âú®ÂÆâÂÖ®ÈÄÄÂá∫...")
            save_progress(i, total)
            break
            
        file_path = xlsx_files[i]
        base_name = os.path.basename(file_path)
        baseline_file = baseline_file_path(base_name)
        
        # Ê™¢Êü•Ë®òÊÜ∂È´î
        if check_memory_limit():
            print(f"‚ö†Ô∏è Ë®òÊÜ∂È´î‰ΩøÁî®ÈáèÈÅéÈ´òÔºåÊö´ÂÅú 10 Áßí...")
            time.sleep(10)
            if check_memory_limit():
                print(f"‚ùå Ë®òÊÜ∂È´î‰ªçÁÑ∂ÈÅéÈ´òÔºåÂÅúÊ≠¢ËôïÁêÜ")
                save_progress(i, total)
                break
        
        # Ë®òÈåÑÊ™îÊ°àËôïÁêÜÊôÇÈñì
        file_start_time = time.time()
        start_time_str = datetime.now().strftime('%H:%M:%S')
        current_memory = get_memory_usage()
        
        print(f"[ÂÆåÊàê {i+1:>2}/{total}] [ÂéüÂßã#{i+1:>2}] ËôïÁêÜ‰∏≠... (Ë®òÊÜ∂È´î: {current_memory:.1f}MB)")
        print(f"  Ê™îÊ°à: {base_name}")
        
        try:
            # Ê™¢Êü•ÊòØÂê¶Ë∑≥ÈÅé
            if skip_force_baseline and is_force_baseline_file(file_path):
                end_time_str = datetime.now().strftime('%H:%M:%S')
                consumed_time = time.time() - file_start_time
                
                print(f"  ÁµêÊûú: [SKIP]")
                print(f"  ÂéüÂõ†: Â±¨Êñº FORCE_BASELINE_ON_FIRST_SEEN")
                print(f"  ÊôÇÈñì: Âæû {start_time_str} Âà∞ {end_time_str} ËÄóÊôÇ {consumed_time:.2f} Áßí")
                print()
                
                skip_count += 1
                save_progress(i + 1, total)
                continue
            
            # üõ°Ô∏è ‰ΩøÁî®Âº∑ÂåñÁöÑ Excel ËÆÄÂèñ
            cell_data = dump_excel_cells_with_timeout(file_path)
            
            if not cell_data and current_processing_file is None:
                # ÂèØËÉΩÊòØË∂ÖÊôÇ‰∫Ü
                print(f"  ÁµêÊûú: [TIMEOUT]")
                print(f"  ÂéüÂõ†: ËôïÁêÜË∂ÖÊôÇÔºåË∑≥ÈÅéÊ≠§Ê™îÊ°à")
                error_count += 1
                save_progress(i + 1, total)
                continue
            
            curr_author = get_excel_last_author(file_path)
            curr_hash = hash_excel_content(cell_data)
            
            # ÂÑ≤Â≠ò baseline
            save_baseline(baseline_file, {
                "last_author": curr_author,
                "content_hash": curr_hash,
                "cells": cell_data
            })
            
            # Ë®àÁÆóÁµêÊûú
            size = os.path.getsize(baseline_file)
            baseline_total_size += size
            end_time_str = datetime.now().strftime('%H:%M:%S')
            consumed_time = time.time() - file_start_time
            baseline_name = os.path.basename(baseline_file)
            
            print(f"  ÁµêÊûú: [OK]")
            print(f"  Baseline: {baseline_name}")
            print(f"  Ê™îÊ°àÂ§ßÂ∞è: {human_readable_size(size)} | Á¥ØÁ©ç: {human_readable_size(baseline_total_size)}")
            print(f"  ÊôÇÈñì: Âæû {start_time_str} Âà∞ {end_time_str} ËÄóÊôÇ {consumed_time:.2f} Áßí")
            print()
            
            success_count += 1
            save_progress(i + 1, total)
            
        except Exception as e:
            end_time_str = datetime.now().strftime('%H:%M:%S')
            consumed_time = time.time() - file_start_time
            
            print(f"  ÁµêÊûú: [ERROR]")
            print(f"  ÈåØË™§: {e}")
            print(f"  ÊôÇÈñì: Âæû {start_time_str} Âà∞ {end_time_str} ËÄóÊôÇ {consumed_time:.2f} Áßí")
            print()
            
            error_count += 1
            save_progress(i + 1, total)
    
    force_stop = True  # ÂÅúÊ≠¢Ë∂ÖÊôÇÁõ£ÊéßÁ∑öÁ®ã
    
    end_time = time.time()
    total_time = end_time - start_time
    
    print("-" * 90)
    print("üéØ BASELINE Âª∫Á´ãÂÆåÊàê!")
    print(f"‚è±Ô∏è  Á∏ΩËÄóÊôÇ: {total_time:.2f} Áßí")
    print(f"‚úÖ ÊàêÂäü: {success_count} ÂÄã")
    print(f"‚è≠Ô∏è  Ë∑≥ÈÅé: {skip_count} ÂÄã")
    print(f"‚ùå Â§±Êïó: {error_count} ÂÄã")
    print(f"üì¶ Á¥ØÁ©ç baseline Ê™îÊ°àÂ§ßÂ∞è: {human_readable_size(baseline_total_size)}")
    
    if success_count > 0:
        print(f"üìä Âπ≥ÂùáÊØèÊ™îÊ°àËôïÁêÜÊôÇÈñì: {total_time/total:.2f} Áßí")
    
    # Ê∏ÖÁêÜÈÄ≤Â∫¶Ê™îÊ°à
    if ENABLE_RESUME and os.path.exists(RESUME_LOG_FILE):
        try:
            os.remove(RESUME_LOG_FILE)
            print(f"üßπ Ê∏ÖÁêÜÈÄ≤Â∫¶Ê™îÊ°à")
        except Exception:
            pass
    
    print()
    print(f"üìÅ ÊâÄÊúâ baseline Ê™îÊ°àÂ≠òÊîæÊñº: {os.path.abspath(LOG_FOLDER)}")
    if USE_LOCAL_CACHE:
        print(f"üíæ Êú¨Âú∞Á∑©Â≠òÊ™îÊ°àÂ≠òÊîæÊñº: {os.path.abspath(CACHE_FOLDER)}")
    print("=" * 90 + "\n")

def print_console_header():
    print("\n" + "="*80)
    print(" Excel File Change Watcher (Ë®∫Êñ∑Âº∑ÂåñÁâàÊú¨) ".center(80, "-"))
    print("="*80 + "\n")

# ============= ÂÖ∂‰ªñÂáΩÊï∏‰øùÊåÅÂéüÊ®£... ============

if __name__ == "__main__":
    try:
        print_console_header()
        print("  Áõ£ÊéßË≥áÊñôÂ§æ:")
        for folder in WATCH_FOLDERS:
            print(f"    - {folder}")
        print(f"  ÊîØÊè¥ÂâØÊ™îÂêç: {SUPPORTED_EXTS}")
        print(f"  ÁõÆÂâç‰ΩøÁî®ËÄÖ: {os.getlogin()}")  # ÊáâË©≤È°ØÁ§∫ ckcm0210
        
        optimizations = []
        if USE_LOCAL_CACHE:
            optimizations.append("Êú¨Âú∞Á∑©Â≠ò")
        if ENABLE_FAST_MODE:
            optimizations.append("Âø´ÈÄüÊ®°Âºè")
        if ENABLE_TIMEOUT:
            optimizations.append(f"Ë∂ÖÊôÇ‰øùË≠∑({FILE_TIMEOUT_SECONDS}s)")
        if ENABLE_MEMORY_MONITOR:
            optimizations.append(f"Ë®òÊÜ∂È´îÁõ£Êéß({MEMORY_LIMIT_MB}MB)")
        if ENABLE_RESUME:
            optimizations.append("Êñ∑ÈªûÁ∫åÂÇ≥")
        
        print(f"  üöÄ ÂïüÁî®ÂäüËÉΩ: {', '.join(optimizations)}")
        print(f"  üìÇ Baseline ÂÑ≤Â≠ò‰ΩçÁΩÆ: {os.path.abspath(LOG_FOLDER)}")
        if USE_LOCAL_CACHE:
            print(f"  üíæ Êú¨Âú∞Á∑©Â≠ò‰ΩçÁΩÆ: {os.path.abspath(CACHE_FOLDER)}")
        
        # Á¢∫‰øùË≥áÊñôÂ§æÂ≠òÂú®
        os.makedirs(LOG_FOLDER, exist_ok=True)
        if USE_LOCAL_CACHE:
            os.makedirs(CACHE_FOLDER, exist_ok=True)

        if SCAN_ALL_MODE:
            all_files = get_all_excel_files(WATCH_FOLDERS)
            print(f"Á∏ΩÂÖ± find Âà∞ {len(all_files)} ÂÄã Excel file.")
            create_baseline_for_files_robust(all_files, skip_force_baseline=True)
            print("baseline scan ÂÆåÊàêÔºÅ\n")
        else:
            target_files = get_all_excel_files(MANUAL_BASELINE_TARGET)
            print(f"ÊâãÂãïÊåáÂÆö baselineÔºåÂêàÂÖ± {len(target_files)} ÂÄã Excel file.")
            create_baseline_for_files_robust(target_files, skip_force_baseline=False)
            print("ÊâãÂãï baseline ÂÆåÊàêÔºÅ\n")

        # ÂÖ∂‰ªñÁõ£ÊéßÁ®ãÂºèÁ¢º...
        
    except Exception as e:
        print(f"[ERROR][main] Á®ãÂºè‰∏ªÊµÅÁ®ã error: {e}")
        import traceback
        traceback.print_exc()
