import os
import time
import csv
import hashlib
import gc
import psutil
import shutil
import tempfile
import gzip
import json
import signal
import threading
from datetime import datetime
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from openpyxl import load_workbook

# =========== User Config ============
SCAN_ALL_MODE = True

# ğŸš€ å„ªåŒ–é¸é …
USE_LOCAL_CACHE = True
ENABLE_FAST_MODE = True
CACHE_FOLDER = r".\\excel_cache"

# ğŸ”§ è¨ºæ–·å’Œæ¢å¾©é¸é …
ENABLE_TIMEOUT = True          # å•Ÿç”¨è¶…æ™‚ä¿è­·
FILE_TIMEOUT_SECONDS = 120     # æ¯å€‹æª”æ¡ˆæœ€å¤§è™•ç†æ™‚é–“ (ç§’)
ENABLE_MEMORY_MONITOR = True   # å•Ÿç”¨è¨˜æ†¶é«”ç›£æ§
MEMORY_LIMIT_MB = 2048         # è¨˜æ†¶é«”é™åˆ¶ (MB)
ENABLE_RESUME = True           # å•Ÿç”¨æ–·é»çºŒå‚³
RESUME_LOG_FILE = r".\\baseline_progress.log"  # é€²åº¦è¨˜éŒ„æª”

WATCH_FOLDERS = [
    r"\\network_drive\\your_folder1",
    r"\\network_drive\\your_folder2"
]

MANUAL_BASELINE_TARGET = [
    r"\\network_drive\\your_folder1\\somefile.xlsx",
    r"\\network_drive\\your_folder2\\subfolder"
]

LOG_FOLDER = r".\\excel_watch_log"
LOG_FILE_DATE = datetime.now().strftime('%Y%m%d')
CSV_LOG_FILE = os.path.join(LOG_FOLDER, f"excel_change_log_{LOG_FILE_DATE}.csv.gz")
SUPPORTED_EXTS = ('.xlsx', '.xlsm')

MAX_RETRY = 10
RETRY_INTERVAL_SEC = 2
USE_TEMP_COPY = True

WHITELIST_USERS = ['ckcm0210', 'yourwhiteuser']
LOG_WHITELIST_USER_CHANGE = True

FORCE_BASELINE_ON_FIRST_SEEN = [
    r"\\network_drive\\your_folder1\\must_first_baseline.xlsx",
    "force_this_file.xlsx"
]
# =========== End User Config ============

# å…¨å±€è®Šæ•¸
current_processing_file = None
processing_start_time = None
force_stop = False

def signal_handler(signum, frame):
    """è™•ç† Ctrl+C ä¸­æ–·"""
    global force_stop
    force_stop = True
    print("\nğŸ›‘ æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨å®‰å…¨åœæ­¢...")
    if current_processing_file:
        print(f"   ç›®å‰è™•ç†æª”æ¡ˆ: {current_processing_file}")

signal.signal(signal.SIGINT, signal_handler)

def get_memory_usage():
    """ç²å–ç›®å‰è¨˜æ†¶é«”ä½¿ç”¨é‡"""
    try:
        process = psutil.Process(os.getpid())
        return process.memory_info().rss / 1024 / 1024  # MB
    except Exception:
        return 0

def check_memory_limit():
    """æª¢æŸ¥è¨˜æ†¶é«”æ˜¯å¦è¶…é™"""
    if not ENABLE_MEMORY_MONITOR:
        return False
    
    current_memory = get_memory_usage()
    if current_memory > MEMORY_LIMIT_MB:
        print(f"âš ï¸ è¨˜æ†¶é«”ä½¿ç”¨é‡éé«˜: {current_memory:.1f} MB > {MEMORY_LIMIT_MB} MB")
        print("   æ­£åœ¨åŸ·è¡Œåƒåœ¾å›æ”¶...")
        gc.collect()
        new_memory = get_memory_usage()
        print(f"   åƒåœ¾å›æ”¶å¾Œ: {new_memory:.1f} MB")
        return new_memory > MEMORY_LIMIT_MB
    return False

def save_progress(completed_files, total_files):
    """å„²å­˜é€²åº¦åˆ°æª”æ¡ˆ"""
    if not ENABLE_RESUME:
        return
    
    try:
        progress_data = {
            "timestamp": datetime.now().isoformat(),
            "completed": completed_files,
            "total": total_files,
            "completed_list": completed_files  # å¯ä»¥æ”¹ç‚ºæª”æ¡ˆåˆ—è¡¨
        }
        
        with open(RESUME_LOG_FILE, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, ensure_ascii=False, indent=2)
            
    except Exception as e:
        print(f"[WARN] ç„¡æ³•å„²å­˜é€²åº¦: {e}")

def load_progress():
    """è¼‰å…¥ä¹‹å‰çš„é€²åº¦"""
    if not ENABLE_RESUME or not os.path.exists(RESUME_LOG_FILE):
        return None
    
    try:
        with open(RESUME_LOG_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"[WARN] ç„¡æ³•è¼‰å…¥é€²åº¦: {e}")
        return None

def timeout_handler():
    """è¶…æ™‚è™•ç†å‡½æ•¸"""
    global current_processing_file, processing_start_time, force_stop
    
    while not force_stop:
        time.sleep(10)  # æ¯ 10 ç§’æª¢æŸ¥ä¸€æ¬¡
        
        if current_processing_file and processing_start_time:
            elapsed = time.time() - processing_start_time
            if elapsed > FILE_TIMEOUT_SECONDS:
                print(f"\nâ° æª”æ¡ˆè™•ç†è¶…æ™‚!")
                print(f"   æª”æ¡ˆ: {current_processing_file}")
                print(f"   å·²è™•ç†æ™‚é–“: {elapsed:.1f} ç§’ > {FILE_TIMEOUT_SECONDS} ç§’")
                print(f"   å°‡è·³éæ­¤æª”æ¡ˆä¸¦ç¹¼çºŒ...")
                # é€™è£¡å¯ä»¥è¨­ç½®ä¸€å€‹æ¨™èªŒä¾†è·³éç•¶å‰æª”æ¡ˆ
                current_processing_file = None
                processing_start_time = None

def get_all_excel_files(folders):
    all_files = []
    for folder in folders:
        if os.path.isfile(folder):
            if folder.lower().endswith(SUPPORTED_EXTS) and not os.path.basename(folder).startswith('~$'):
                all_files.append(folder)
        elif os.path.isdir(folder):
            for dirpath, _, filenames in os.walk(folder):
                for f in filenames:
                    if f.lower().endswith(SUPPORTED_EXTS) and not f.startswith('~$'):
                        all_files.append(os.path.join(dirpath, f))
    return all_files

def serialize_cell_value(value):
    """å¿«é€Ÿåºåˆ—åŒ–"""
    if value is None:
        return None
    elif isinstance(value, datetime):
        return value.isoformat()
    elif isinstance(value, (int, float, str, bool)):
        return value
    else:
        return str(value)

def get_excel_last_author(path):
    try:
        wb = load_workbook(path, read_only=True)
        author = wb.properties.lastModifiedBy
        wb.close()
        return author
    except Exception:
        return None

def copy_to_cache(network_path):
    """ğŸš€ å¸¶è¨ºæ–·çš„ç·©å­˜åŠŸèƒ½"""
    if not USE_LOCAL_CACHE:
        return network_path
    
    try:
        os.makedirs(CACHE_FOLDER, exist_ok=True)
        
        # æª¢æŸ¥åŸå§‹æª”æ¡ˆæ˜¯å¦å­˜åœ¨å’Œå¯è®€
        if not os.path.exists(network_path):
            raise FileNotFoundError(f"ç¶²çµ¡æª”æ¡ˆä¸å­˜åœ¨: {network_path}")
        
        if not os.access(network_path, os.R_OK):
            raise PermissionError(f"ç„¡æ³•è®€å–ç¶²çµ¡æª”æ¡ˆ: {network_path}")
        
        file_hash = hashlib.md5(network_path.encode('utf-8')).hexdigest()[:16]
        cache_file = os.path.join(CACHE_FOLDER, f"{file_hash}_{os.path.basename(network_path)}")
        
        # æª¢æŸ¥ç·©å­˜
        if os.path.exists(cache_file):
            try:
                network_mtime = os.path.getmtime(network_path)
                cache_mtime = os.path.getmtime(cache_file)
                if cache_mtime >= network_mtime:
                    return cache_file
            except Exception:
                pass
        
        # è¤‡è£½æª”æ¡ˆï¼Œé¡¯ç¤ºé€²åº¦
        network_size = os.path.getsize(network_path)
        print(f"   ğŸ“¥ è¤‡è£½åˆ°ç·©å­˜: {os.path.basename(network_path)} ({network_size/(1024*1024):.1f} MB)")
        
        copy_start = time.time()
        shutil.copy2(network_path, cache_file)
        copy_time = time.time() - copy_start
        
        print(f"      è¤‡è£½å®Œæˆï¼Œè€—æ™‚ {copy_time:.1f} ç§’")
        return cache_file
        
    except Exception as e:
        print(f"   âŒ ç·©å­˜å¤±æ•—: {e}")
        return network_path

def dump_excel_cells_with_timeout(path):
    """ğŸš€ å¸¶è¶…æ™‚ä¿è­·çš„ Excel è®€å–"""
    global current_processing_file, processing_start_time
    
    current_processing_file = path
    processing_start_time = time.time()
    
    try:
        # æª¢æŸ¥æª”æ¡ˆåŸºæœ¬è³‡è¨Š
        file_size = os.path.getsize(path)
        print(f"   ğŸ“Š æª”æ¡ˆå¤§å°: {file_size/(1024*1024):.1f} MB")
        
        # ä½¿ç”¨æœ¬åœ°ç·©å­˜
        local_path = copy_to_cache(path)
        
        if ENABLE_FAST_MODE:
            # å¿«é€Ÿæ¨¡å¼
            print(f"   ğŸš€ ä½¿ç”¨å¿«é€Ÿæ¨¡å¼è®€å–...")
            wb = load_workbook(local_path, read_only=True, data_only=False)
            result = {}
            
            worksheet_count = len(wb.worksheets)
            print(f"   ğŸ“‹ å·¥ä½œè¡¨æ•¸é‡: {worksheet_count}")
            
            for idx, ws in enumerate(wb.worksheets, 1):
                print(f"      è™•ç†å·¥ä½œè¡¨ {idx}/{worksheet_count}: {ws.title}")
                
                ws_data = {}
                cell_count = 0
                
                if ws.max_row > 1 or ws.max_column > 1:
                    for row in ws.iter_rows(min_row=1, max_row=ws.max_row, 
                                          min_col=1, max_col=ws.max_column):
                        for cell in row:
                            if cell.value is not None:
                                formula = None
                                if cell.data_type == "f":
                                    formula = str(cell.value)
                                    if not formula.startswith("="):
                                        formula = "=" + formula
                                
                                ws_data[cell.coordinate] = {
                                    "formula": formula,
                                    "value": serialize_cell_value(cell.value)
                                }
                                cell_count += 1
                
                print(f"         æ‰¾åˆ° {cell_count} å€‹æœ‰è³‡æ–™çš„ cell")
                
                if ws_data:
                    result[ws.title] = ws_data
            
            wb.close()
            print(f"   âœ… Excel è®€å–å®Œæˆ")
        else:
            # æ¨™æº–æ¨¡å¼
            print(f"   ğŸ“š ä½¿ç”¨æ¨™æº–æ¨¡å¼è®€å–...")
            wb_formula = load_workbook(local_path, data_only=False)
            wb_value = load_workbook(local_path, data_only=True)
            result = {}
            
            for ws_formula, ws_value in zip(wb_formula.worksheets, wb_value.worksheets):
                ws_data = {}
                for row_formula, row_value in zip(ws_formula.iter_rows(), ws_value.iter_rows()):
                    for cell_formula, cell_value in zip(row_formula, row_value):
                        try:
                            formula = cell_formula.value if cell_formula.data_type == "f" else None
                            value = serialize_cell_value(cell_value.value)
                            
                            if formula or (value not in [None, ""]):
                                if formula is not None:
                                    formula = str(formula)
                                    if not formula.startswith("="):
                                        formula = "=" + formula
                                    if not formula.startswith("'="):
                                        formula = "'" + formula
                                ws_data[cell_formula.coordinate] = {
                                    "formula": formula,
                                    "value": value
                                }
                        except Exception:
                            pass
                
                if ws_data:
                    result[ws_formula.title] = ws_data
            
            wb_formula.close()
            wb_value.close()
        
        current_processing_file = None
        processing_start_time = None
        return result
        
    except Exception as e:
        current_processing_file = None
        processing_start_time = None
        print(f"   âŒ Excel è®€å–å¤±æ•—: {e}")
        return {}

def hash_excel_content(cells_dict):
    try:
        content_str = json.dumps(cells_dict, sort_keys=True, ensure_ascii=False)
        return hashlib.md5(content_str.encode('utf-8')).hexdigest()
    except Exception:
        return None

def baseline_file_path(base_name):
    return os.path.join(LOG_FOLDER, f"{base_name}.baseline.json.gz")

def save_baseline(baseline_file, data):
    try:
        with gzip.open(baseline_file, 'wt', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, separators=(',', ':'))
    except Exception as e:
        print(f"[ERROR][save_baseline] error saving {baseline_file}: {e}")

def is_force_baseline_file(filepath):
    try:
        lowerfile = filepath.lower()
        for pattern in FORCE_BASELINE_ON_FIRST_SEEN:
            if pattern.lower() in lowerfile:
                return True
        return False
    except Exception:
        return False

def human_readable_size(num_bytes):
    for unit in ['B','KB','MB','GB','TB']:
        if num_bytes < 1024.0:
            return f"{num_bytes:,.2f} {unit}"
        num_bytes /= 1024.0
    return f"{num_bytes:.2f} PB"

def create_baseline_for_files_robust(xlsx_files, skip_force_baseline=True):
    """ğŸ›¡ï¸ å¼·åŒ–ç‰ˆ baseline å»ºç«‹ï¼Œå¸¶è¨ºæ–·å’Œæ¢å¾©åŠŸèƒ½"""
    global force_stop
    
    total = len(xlsx_files)
    if total == 0:
        print("[INFO] æ²’æœ‰éœ€è¦ baseline çš„æª”æ¡ˆã€‚")
        return

    print()
    print("=" * 90)
    print(" BASELINE å»ºç«‹ç¨‹åº (å¼·åŒ–è¨ºæ–·ç‰ˆæœ¬) ".center(90, "="))
    print("=" * 90)
    
    # æª¢æŸ¥æ˜¯å¦æœ‰ä¹‹å‰çš„é€²åº¦
    progress = load_progress()
    start_index = 0
    if progress and ENABLE_RESUME:
        print(f"ğŸ”„ ç™¼ç¾ä¹‹å‰çš„é€²åº¦è¨˜éŒ„:")
        print(f"   ä¹‹å‰å®Œæˆ: {progress['completed']}/{progress['total']}")
        print(f"   è¨˜éŒ„æ™‚é–“: {progress['timestamp']}")
        
        resume = input("æ˜¯å¦è¦å¾ä¸Šæ¬¡ä¸­æ–·çš„åœ°æ–¹ç¹¼çºŒ? (y/n): ").strip().lower()
        if resume == 'y':
            start_index = progress['completed']
            print(f"   âœ… å¾ç¬¬ {start_index + 1} å€‹æª”æ¡ˆé–‹å§‹")
    
    # å•Ÿå‹•è¶…æ™‚ç›£æ§ç·šç¨‹
    if ENABLE_TIMEOUT:
        timeout_thread = threading.Thread(target=timeout_handler, daemon=True)
        timeout_thread.start()
        print(f"â° å•Ÿç”¨è¶…æ™‚ä¿è­·: {FILE_TIMEOUT_SECONDS} ç§’")
    
    if ENABLE_MEMORY_MONITOR:
        print(f"ğŸ’¾ å•Ÿç”¨è¨˜æ†¶é«”ç›£æ§: {MEMORY_LIMIT_MB} MB")
    
    optimizations = []
    if USE_LOCAL_CACHE:
        optimizations.append("æœ¬åœ°ç·©å­˜")
    if ENABLE_FAST_MODE:
        optimizations.append("å¿«é€Ÿæ¨¡å¼")
    
    print(f"ğŸš€ å•Ÿç”¨å„ªåŒ–: {', '.join(optimizations)}")
    print(f"ğŸ“‚ Baseline å„²å­˜ä½ç½®: {os.path.abspath(LOG_FOLDER)}")
    if USE_LOCAL_CACHE:
        print(f"ğŸ’¾ æœ¬åœ°ç·©å­˜ä½ç½®: {os.path.abspath(CACHE_FOLDER)}")
    print(f"ğŸ“‹ è¦è™•ç†çš„æª”æ¡ˆ: {total} å€‹ Excel (å¾ç¬¬ {start_index + 1} å€‹é–‹å§‹)")
    print(f"â° é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    print("-" * 90)
    
    # ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨
    os.makedirs(LOG_FOLDER, exist_ok=True)
    if USE_LOCAL_CACHE:
        os.makedirs(CACHE_FOLDER, exist_ok=True)
    
    baseline_total_size = 0
    success_count = 0
    skip_count = 0
    error_count = 0
    start_time = time.time()
    
    for i in range(start_index, total):
        if force_stop:
            print("\nğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡è™Ÿï¼Œæ­£åœ¨å®‰å…¨é€€å‡º...")
            save_progress(i, total)
            break
            
        file_path = xlsx_files[i]
        base_name = os.path.basename(file_path)
        baseline_file = baseline_file_path(base_name)
        
        # æª¢æŸ¥è¨˜æ†¶é«”
        if check_memory_limit():
            print(f"âš ï¸ è¨˜æ†¶é«”ä½¿ç”¨é‡éé«˜ï¼Œæš«åœ 10 ç§’...")
            time.sleep(10)
            if check_memory_limit():
                print(f"âŒ è¨˜æ†¶é«”ä»ç„¶éé«˜ï¼Œåœæ­¢è™•ç†")
                save_progress(i, total)
                break
        
        # è¨˜éŒ„æª”æ¡ˆè™•ç†æ™‚é–“
        file_start_time = time.time()
        start_time_str = datetime.now().strftime('%H:%M:%S')
        current_memory = get_memory_usage()
        
        print(f"[å®Œæˆ {i+1:>2}/{total}] [åŸå§‹#{i+1:>2}] è™•ç†ä¸­... (è¨˜æ†¶é«”: {current_memory:.1f}MB)")
        print(f"  æª”æ¡ˆ: {base_name}")
        
        try:
            # æª¢æŸ¥æ˜¯å¦è·³é
            if skip_force_baseline and is_force_baseline_file(file_path):
                end_time_str = datetime.now().strftime('%H:%M:%S')
                consumed_time = time.time() - file_start_time
                
                print(f"  çµæœ: [SKIP]")
                print(f"  åŸå› : å±¬æ–¼ FORCE_BASELINE_ON_FIRST_SEEN")
                print(f"  æ™‚é–“: å¾ {start_time_str} åˆ° {end_time_str} è€—æ™‚ {consumed_time:.2f} ç§’")
                print()
                
                skip_count += 1
                save_progress(i + 1, total)
                continue
            
            # ğŸ›¡ï¸ ä½¿ç”¨å¼·åŒ–çš„ Excel è®€å–
            cell_data = dump_excel_cells_with_timeout(file_path)
            
            if not cell_data and current_processing_file is None:
                # å¯èƒ½æ˜¯è¶…æ™‚äº†
                print(f"  çµæœ: [TIMEOUT]")
                print(f"  åŸå› : è™•ç†è¶…æ™‚ï¼Œè·³éæ­¤æª”æ¡ˆ")
                error_count += 1
                save_progress(i + 1, total)
                continue
            
            curr_author = get_excel_last_author(file_path)
            curr_hash = hash_excel_content(cell_data)
            
            # å„²å­˜ baseline
            save_baseline(baseline_file, {
                "last_author": curr_author,
                "content_hash": curr_hash,
                "cells": cell_data
            })
            
            # è¨ˆç®—çµæœ
            size = os.path.getsize(baseline_file)
            baseline_total_size += size
            end_time_str = datetime.now().strftime('%H:%M:%S')
            consumed_time = time.time() - file_start_time
            baseline_name = os.path.basename(baseline_file)
            
            print(f"  çµæœ: [OK]")
            print(f"  Baseline: {baseline_name}")
            print(f"  æª”æ¡ˆå¤§å°: {human_readable_size(size)} | ç´¯ç©: {human_readable_size(baseline_total_size)}")
            print(f"  æ™‚é–“: å¾ {start_time_str} åˆ° {end_time_str} è€—æ™‚ {consumed_time:.2f} ç§’")
            print()
            
            success_count += 1
            save_progress(i + 1, total)
            
        except Exception as e:
            end_time_str = datetime.now().strftime('%H:%M:%S')
            consumed_time = time.time() - file_start_time
            
            print(f"  çµæœ: [ERROR]")
            print(f"  éŒ¯èª¤: {e}")
            print(f"  æ™‚é–“: å¾ {start_time_str} åˆ° {end_time_str} è€—æ™‚ {consumed_time:.2f} ç§’")
            print()
            
            error_count += 1
            save_progress(i + 1, total)
    
    force_stop = True  # åœæ­¢è¶…æ™‚ç›£æ§ç·šç¨‹
    
    end_time = time.time()
    total_time = end_time - start_time
    
    print("-" * 90)
    print("ğŸ¯ BASELINE å»ºç«‹å®Œæˆ!")
    print(f"â±ï¸  ç¸½è€—æ™‚: {total_time:.2f} ç§’")
    print(f"âœ… æˆåŠŸ: {success_count} å€‹")
    print(f"â­ï¸  è·³é: {skip_count} å€‹")
    print(f"âŒ å¤±æ•—: {error_count} å€‹")
    print(f"ğŸ“¦ ç´¯ç© baseline æª”æ¡ˆå¤§å°: {human_readable_size(baseline_total_size)}")
    
    if success_count > 0:
        print(f"ğŸ“Š å¹³å‡æ¯æª”æ¡ˆè™•ç†æ™‚é–“: {total_time/total:.2f} ç§’")
    
    # æ¸…ç†é€²åº¦æª”æ¡ˆ
    if ENABLE_RESUME and os.path.exists(RESUME_LOG_FILE):
        try:
            os.remove(RESUME_LOG_FILE)
            print(f"ğŸ§¹ æ¸…ç†é€²åº¦æª”æ¡ˆ")
        except Exception:
            pass
    
    print()
    print(f"ğŸ“ æ‰€æœ‰ baseline æª”æ¡ˆå­˜æ”¾æ–¼: {os.path.abspath(LOG_FOLDER)}")
    if USE_LOCAL_CACHE:
        print(f"ğŸ’¾ æœ¬åœ°ç·©å­˜æª”æ¡ˆå­˜æ”¾æ–¼: {os.path.abspath(CACHE_FOLDER)}")
    print("=" * 90 + "\n")

def print_console_header():
    print("\n" + "="*80)
    print(" Excel File Change Watcher (è¨ºæ–·å¼·åŒ–ç‰ˆæœ¬) ".center(80, "-"))
    print("="*80 + "\n")

# ============= å…¶ä»–å‡½æ•¸ä¿æŒåŸæ¨£... ============

if __name__ == "__main__":
    try:
        print_console_header()
        print("  ç›£æ§è³‡æ–™å¤¾:")
        for folder in WATCH_FOLDERS:
            print(f"    - {folder}")
        print(f"  æ”¯æ´å‰¯æª”å: {SUPPORTED_EXTS}")
        print(f"  ç›®å‰ä½¿ç”¨è€…: {os.getlogin()}")  # æ‡‰è©²é¡¯ç¤º ckcm0210
        
        optimizations = []
        if USE_LOCAL_CACHE:
            optimizations.append("æœ¬åœ°ç·©å­˜")
        if ENABLE_FAST_MODE:
            optimizations.append("å¿«é€Ÿæ¨¡å¼")
        if ENABLE_TIMEOUT:
            optimizations.append(f"è¶…æ™‚ä¿è­·({FILE_TIMEOUT_SECONDS}s)")
        if ENABLE_MEMORY_MONITOR:
            optimizations.append(f"è¨˜æ†¶é«”ç›£æ§({MEMORY_LIMIT_MB}MB)")
        if ENABLE_RESUME:
            optimizations.append("æ–·é»çºŒå‚³")
        
        print(f"  ğŸš€ å•Ÿç”¨åŠŸèƒ½: {', '.join(optimizations)}")
        print(f"  ğŸ“‚ Baseline å„²å­˜ä½ç½®: {os.path.abspath(LOG_FOLDER)}")
        if USE_LOCAL_CACHE:
            print(f"  ğŸ’¾ æœ¬åœ°ç·©å­˜ä½ç½®: {os.path.abspath(CACHE_FOLDER)}")
        
        # ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨
        os.makedirs(LOG_FOLDER, exist_ok=True)
        if USE_LOCAL_CACHE:
            os.makedirs(CACHE_FOLDER, exist_ok=True)

        if SCAN_ALL_MODE:
            all_files = get_all_excel_files(WATCH_FOLDERS)
            print(f"ç¸½å…± find åˆ° {len(all_files)} å€‹ Excel file.")
            create_baseline_for_files_robust(all_files, skip_force_baseline=True)
            print("baseline scan å®Œæˆï¼\n")
        else:
            target_files = get_all_excel_files(MANUAL_BASELINE_TARGET)
            print(f"æ‰‹å‹•æŒ‡å®š baselineï¼Œåˆå…± {len(target_files)} å€‹ Excel file.")
            create_baseline_for_files_robust(target_files, skip_force_baseline=False)
            print("æ‰‹å‹• baseline å®Œæˆï¼\n")

        # å…¶ä»–ç›£æ§ç¨‹å¼ç¢¼...
        
    except Exception as e:
        print(f"[ERROR][main] ç¨‹å¼ä¸»æµç¨‹ error: {e}")
        import traceback
        traceback.print_exc()
