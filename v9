import os
import time
import csv
import hashlib
import gc
import psutil
import shutil
import gzip
import json
import signal
import threading
import tempfile
import re
import zipfile
import xml.etree.ElementTree as ET
from datetime import datetime
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from openpyxl import load_workbook
from openpyxl.worksheet.formula import ArrayFormula
import builtins
from io import StringIO
from wcwidth import wcswidth, wcwidth

# =========== User Config ============
SCAN_ALL_MODE = True
USE_LOCAL_CACHE = True
CACHE_FOLDER = r"C:\Users\user\Desktop\watchdog\cache_folder"
ENABLE_FAST_MODE = True
ENABLE_TIMEOUT = True
FILE_TIMEOUT_SECONDS = 120
ENABLE_MEMORY_MONITOR = True
MEMORY_LIMIT_MB = 2048
ENABLE_RESUME = True
FORMULA_ONLY_MODE = True
DEBOUNCE_INTERVAL_SEC = 2  # å¹¾ç§’å…§é‡è¦† event æœƒè¢«å¿½ç•¥ï¼Œå¯è‡ªè¡Œèª¿æ•´
RESUME_LOG_FILE = r"C:\Users\user\Desktop\watchdog\resume_log\baseline_progress.log"
WATCH_FOLDERS = [
    r"C:\Users\user\Desktop\Test",
]
MANUAL_BASELINE_TARGET = []
LOG_FOLDER = r"C:\Users\user\Desktop\watchdog\log_folder"
LOG_FILE_DATE = datetime.now().strftime('%Y%m%d')
CSV_LOG_FILE = os.path.join(LOG_FOLDER, f"excel_change_log_{LOG_FILE_DATE}.csv.gz")
SUPPORTED_EXTS = ('.xlsx', '.xlsm')
MAX_RETRY = 10
RETRY_INTERVAL_SEC = 2
USE_TEMP_COPY = True
WHITELIST_USERS = ['ckcm0210', 'yourwhiteuser']
LOG_WHITELIST_USER_CHANGE = True
FORCE_BASELINE_ON_FIRST_SEEN = [
    r"\\network_drive\\your_folder1\\must_first_baseline.xlsx",
    "force_this_file.xlsx"
]
# =========== Polling Config ============
POLLING_SIZE_THRESHOLD_MB = 10  # å¹¾å¤šMBä»¥ä¸Šç®—å¤§file
DENSE_POLLING_INTERVAL_SEC = 5  # ç´°fileå¹¾å¤šç§’pollä¸€æ¬¡
DENSE_POLLING_DURATION_SEC = 15 # ç´°fileé€£çºŒpollå¹¾è€
SPARSE_POLLING_INTERVAL_SEC = 15 # å¤§fileå¹¾å¤šç§’pollä¸€æ¬¡ï¼ˆå†·éœæœŸï¼‰
SPARSE_POLLING_DURATION_SEC = 15 # å¤§fileå†·éœæœŸæ™‚é•·ï¼ˆé€šå¸¸åŒintervalä¸€æ¨£ï¼‰
# =========== End Polling Config ============
# =========== End User Config ============

# ============ PATCH: Override print for timestamping ============      
_original_print = builtins.print
        
def timestamped_print(*args, **kwargs):
    # å¦‚æœæœ‰ file=... åƒæ•¸ï¼Œç›´æ¥ç”¨åŸç”Ÿ print
    if 'file' in kwargs:
        _original_print(*args, **kwargs)
        return

    output_buffer = StringIO()
    _original_print(*args, file=output_buffer, **kwargs)
    message = output_buffer.getvalue()
    output_buffer.close()

    if not message.strip():
        _original_print(message, end='')
        return

    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    lines = message.rstrip().split('\n')
    if lines and not lines[0]:
        _original_print(f"[{timestamp}]")
        lines = lines[1:]
    timestamped_message = '\n'.join(f"[{timestamp}] {line}" for line in lines if line)
    _original_print(timestamped_message)

builtins.print = timestamped_print
# ============ END PATCH ============
def wrap_text_with_cjk_support(text, width):
    """
    è‡ªç ”çš„ã€æ”¯æŒ CJK å­—ç¬¦å¯¬åº¦çš„æ™ºèƒ½æ–‡æœ¬æ›è¡Œå‡½æ•¸ã€‚
    å¾¹åº•å–ä»£ textwrapã€‚
    """
    lines = []
    line = ""
    current_width = 0
    for char in text:
        char_width = wcwidth(char)
        if char_width < 0: continue # è·³éæ§åˆ¶å­—ç¬¦

        if current_width + char_width > width:
            lines.append(line)
            line = char
            current_width = char_width
        else:
            line += char
            current_width += char_width
    if line:
        lines.append(line)
    return lines or ['']

# è¼”åŠ©å‡½æ•¸ï¼šç²¾æº–è¨ˆç®—å­—ä¸²åœ¨çµ‚ç«¯æ©Ÿä¸­é¡¯ç¤ºçš„é—Šåº¦
def _get_display_width(text):
    """
    ç²¾æº–è¨ˆç®—ä¸€å€‹å­—ä¸²çš„é¡¯ç¤ºé—Šåº¦ï¼Œè™•ç† CJK å…¨å½¢å­—å…ƒã€‚
    """
    # wcswidth æ˜¯å°ˆé–€ç”¨ä¾†è¨ˆç®—å­—ä¸²åœ¨çµ‚ç«¯é¡¯ç¤ºé—Šåº¦çš„åº«ï¼Œæ¯”é€å€‹å­—å…ƒè¨ˆç®—æ›´é«˜æ•ˆæº–ç¢º
    return wcswidth(str(text))

def print_aligned_console_diff(old_data, new_data, file_info=None):
    """
    å…¨æ–°ç‰ˆæœ¬çš„ä¸‰æ¬„å¼é¡¯ç¤ºï¼Œèƒ½å®Œç¾è™•ç†ä¸­è‹±æ–‡å°é½Šå•é¡Œã€‚
    Address æ¬„å›ºå®šä¸€å€‹è¼ƒå°çš„é—Šåº¦ï¼Œå‰©é¤˜ç©ºé–“ç”± Baseline å’Œ Current å¹³å‡åˆ†äº«ã€‚
    """
    # å˜—è©¦ç²å–çµ‚ç«¯æ©Ÿçš„é—Šåº¦ï¼Œå¦‚æœå¤±æ•—å‰‡ä½¿ç”¨ä¸€å€‹é è¨­å€¼
    try:
        term_width = os.get_terminal_size().columns
    except OSError:
        term_width = 120 # é è¨­é—Šåº¦

    # --- å…¨æ–°ã€æ›´æ™ºèƒ½çš„æ¬„ä½é—Šåº¦è¨ˆç®— ---
    # ç‚º Address è¨­å®šä¸€å€‹åˆç†çš„å›ºå®šé—Šåº¦
    address_col_width = 12
    # å…©å€‹åˆ†éš”ç¬¦ ' | ' å…±ä½” 4 å€‹å­—å…ƒä½
    separators_width = 4
    # è¨ˆç®—å‰©é¤˜å¯ç”¨æ–¼å…§å®¹é¡¯ç¤ºçš„é—Šåº¦
    remaining_width = term_width - address_col_width - separators_width
    
    # å°‡å‰©é¤˜ç©ºé–“ç›¡é‡å¹³å‡åˆ†é…çµ¦ Baseline å’Œ Current
    baseline_col_width = remaining_width // 2
    # Current æ¬„ä½å¾—åˆ°å‰©é¤˜çš„éƒ¨åˆ†ï¼Œå¯ä»¥è™•ç†å–®æ•¸é—Šåº¦çš„æƒ…æ³
    current_col_width = remaining_width - baseline_col_width

    # --- è¼”åŠ©å‡½æ•¸ï¼Œç”¨æ–¼æ–‡å­—æ›è¡Œ ---
    def wrap_text(text, width):
        lines = []
        current_line = ""
        current_width = 0
        for char in str(text):
            # ä½¿ç”¨ wcwidth ç²å–å–®å€‹å­—å…ƒçš„é—Šåº¦
            char_width = wcwidth(char)
            if char_width < 0: # å¿½ç•¥æ§åˆ¶å­—å…ƒ
                continue
            
            if current_width + char_width > width:
                lines.append(current_line)
                current_line = char
                current_width = char_width
            else:
                current_line += char
                current_width += char_width
        
        if current_line:
            lines.append(current_line)
        # å¦‚æœè¼¸å…¥æ˜¯ç©ºå­—ä¸²ï¼Œç¢ºä¿è¿”å›ä¸€å€‹åŒ…å«ç©ºå­—ä¸²çš„åˆ—è¡¨ï¼Œä»¥ä½”æ“šä¸€è¡Œ
        return lines or ['']

    # --- è¼”åŠ©å‡½æ•¸ï¼Œç”¨æ–¼å°‡å–®è¡Œæ–‡å­—å¡«å……åˆ°æŒ‡å®šé—Šåº¦ ---
    def pad_line(line, width):
        # è¨ˆç®—ç›®å‰è¡Œçš„å¯¦éš›é¡¯ç¤ºé—Šåº¦
        line_width = _get_display_width(line)
        # è¨ˆç®—éœ€è¦å¡«å……çš„ç©ºæ ¼æ•¸é‡
        padding = width - line_width
        # è¿”å›å¡«å……å¾Œçš„å­—ä¸²
        return line + ' ' * padding if padding > 0 else line

    # ==================== é–‹å§‹æ‰“å°è¼¸å‡º ====================
    
    print("=" * term_width)
    
    # æ‰“å°æª”æ¡ˆå’Œå·¥ä½œè¡¨æ¨™é¡Œ
    if file_info:
        filename = file_info.get('filename', 'Unknown')
        worksheet = file_info.get('worksheet', '')
        caption = f"{filename} [Worksheet: {worksheet}]" if worksheet else filename
        # æ¨™é¡Œä¹Ÿéœ€è¦æ”¯æ´æ›è¡Œ
        for cap_line in wrap_text(caption, term_width):
            print(cap_line)
        print("=" * term_width)

    # æ‰“å°è¡¨é ­
    baseline_time = file_info.get('baseline_time', 'N/A')
    current_time = file_info.get('current_time', 'N/A')
    
    header_addr = pad_line("Address", address_col_width)
    header_base = pad_line(f"Baseline ({baseline_time})", baseline_col_width)
    header_curr = pad_line(f"Current ({current_time})", current_col_width)
    print(f"{header_addr} | {header_base} | {header_curr}")
    print("-" * term_width)

    # æº–å‚™æ•¸æ“šé€²è¡Œæ¯”è¼ƒ
    all_keys = sorted(list(set(old_data.keys()) | set(new_data.keys())))

    if not all_keys:
        print("(No cell changes)")
    else:
        for key in all_keys:
            old_val = old_data.get(key)
            new_val = new_data.get(key)
            
            # æº–å‚™é¡¯ç¤ºçš„æ–‡å­—
            if old_val is not None and new_val is not None:
                old_text = f"'{old_val}'"
                new_text = f"[MOD] '{new_val}'" if old_val != new_val else f"'{new_val}'"
            elif old_val is not None:
                old_text = f"'{old_val}'"
                new_text = "[DEL] (Deleted)"
            else:
                old_text = "(Empty)"
                new_text = f"[ADD] '{new_val}'"

            # å°ä¸‰æ¬„çš„å…§å®¹åˆ†åˆ¥é€²è¡Œæ–‡å­—æ›è¡Œ
            addr_lines = wrap_text(key, address_col_width)
            old_lines = wrap_text(old_text, baseline_col_width)
            new_lines = wrap_text(new_text, current_col_width)

            # è¨ˆç®—éœ€è¦æ‰“å°çš„æœ€å¤§è¡Œæ•¸
            num_lines = max(len(addr_lines), len(old_lines), len(new_lines))

            # é€è¡Œæ‰“å°ï¼Œç¢ºä¿æ¯ä¸€è¡Œéƒ½å°é½Š
            for i in range(num_lines):
                # å¾æ›è¡Œå¾Œçš„åˆ—è¡¨ä¸­å–å‡ºå°æ‡‰è¡Œçš„æ–‡å­—ï¼Œå¦‚æœè©²æ¬„æ²’æœ‰é‚£éº¼å¤šè¡Œï¼Œå‰‡ç‚ºç©ºå­—ä¸²
                a_line = addr_lines[i] if i < len(addr_lines) else ""
                o_line = old_lines[i] if i < len(old_lines) else ""
                n_line = new_lines[i] if i < len(new_lines) else ""

                # å°æ¯ä¸€è¡Œçš„æ–‡å­—é€²è¡Œå¡«å……ï¼Œä½¿å…¶é”åˆ°è©²æ¬„çš„é—Šåº¦
                formatted_a = pad_line(a_line, address_col_width)
                formatted_o = pad_line(o_line, baseline_col_width)
                # Current æ¬„ä½ä¸éœ€è¦å¡«å……ï¼Œå› ç‚ºå®ƒæ˜¯æœ€å³é‚Šçš„ä¸€æ¬„
                formatted_n = n_line

                print(f"{formatted_a} | {formatted_o} | {formatted_n}")

    print("-" * term_width)
    
def extract_external_refs(xlsx_path):
    """ è§£æ Excel xlsx ä¸­ external reference mapping: [n] -> è·¯å¾‘ """
    ref_map = {}
    try:
        with zipfile.ZipFile(xlsx_path, 'r') as z:
            rels = ET.fromstring(z.read('xl/_rels/workbook.xml.rels'))
            for rel in rels.findall('{http://schemas.openxmlformats.org/package/2006/relationships}Relationship'):
                if rel.attrib['Type'].endswith('/externalLink'):
                    target = rel.attrib['Target']
                    m = re.search(r'externalLink(\d+)\.xml', target)
                    if m:
                        num = int(m.group(1))
                        try:
                            link_xml = z.read(f'xl/{target}')
                            link_tree = ET.fromstring(link_xml)
                            book_elem = link_tree.find('.//{http://schemas.openxmlformats.org/spreadsheetml/2006/main}externalBookPr')
                            if book_elem is not None:
                                path = book_elem.attrib.get('href', '')
                            else:
                                path = ''
                            ref_map[num] = path
                        except Exception:
                            ref_map[num] = ''
    except Exception:
        pass
    return ref_map

def pretty_formula(formula, ref_map=None):
    """ é¡¯ç¤º formula æ™‚ï¼Œå¦‚æœæœ‰ [n]Table! é€™ç¨® external workbook referenceï¼Œæœƒé¡¯ç¤ºä¾†æºè·¯å¾‘ """
    if formula is None:
        return None
    
    # ä¿®æ”¹ï¼šè™•ç† ArrayFormula ç‰©ä»¶
    if isinstance(formula, ArrayFormula):
        formula_str = formula.text if hasattr(formula, 'text') else str(formula)
    else:
        formula_str = str(formula)
    
    if ref_map:
        def repl(m):
            n = int(m.group(1))
            path = ref_map.get(n, '')
            if path:
                return f"[å¤–éƒ¨æª”æ¡ˆ{n}: {path}]{m.group(0)}"
            else:
                return m.group(0)
        return re.sub(r'\[(\d+)\][A-Za-z0-9_]+!', repl, formula_str)
    else:
        return formula_str

def get_cell_formula(cell):
    """
    å–å¾— cell å…¬å¼ï¼ˆä¸è«–ä¿‚æ™®é€š formula or array formulaï¼‰ï¼Œä¸€å¾‹å›å‚³å…¬å¼å­—ä¸²
    """
    if cell.data_type == 'f':
        if isinstance(cell.value, ArrayFormula):
            # ä¿®æ”¹ï¼šè¿”å› ArrayFormula çš„å¯¦éš›å…¬å¼å­—ç¬¦ä¸²ï¼Œè€Œä¸æ˜¯ç‰©ä»¶
            return cell.value.text if hasattr(cell.value, 'text') else str(cell.value)
        return cell.value
    return None

def should_filter_change(change):
    """
    - æ™®é€šcellï¼ˆå†‡formulaï¼‰ï¼šåªè¦valueæœ‰è®Šå°±è¦å ±
    - æœ‰formulaå˜…cellï¼šåªè¦formulaæœ‰è®Šå°±è¦å ±ï¼Œvalueè®Šå””å ±
    """
    old_f, new_f = change.get('old_formula'), change.get('new_formula')
    old_v, new_v = change.get('old_value'), change.get('new_value')
    if (old_f is None) and (new_f is None):
        # æ™®é€šcellï¼Œåªè¦valueæœ‰è®Šå°±è¦å ±
        return old_v == new_v
    else:
        # æœ‰formulaï¼Œformulaå†‡è®Šå°±å””å ±
        return old_f == new_f

def is_array_formula_obj(val):
    """
    åˆ¤æ–·æ˜¯å¦ openpyxl ArrayFormula ç‰©ä»¶
    """
    return isinstance(val, ArrayFormula)

def filter_array_formula_change(change):
    """
    å°æ–¼ formula èˆŠæ–°éƒ½ä¿‚ Noneï¼ˆç„¡å…¬å¼ï¼‰ï¼Œæˆ–è€… formula string å®Œå…¨ç›¸åŒï¼Œå°±å””éœ€è¦é¡¯ç¤º
    åªè¦ formula string æœ‰è®Šï¼Œå””ç†ä¿‚å’ª array formulaï¼Œéƒ½é¡¯ç¤º
    """
    old_f, new_f = change.get('old_formula'), change.get('new_formula')
    if old_f == new_f:
        return True
    return False

def enrich_formula_external_path(change, ref_map):
    """
    å°‡ [n]Table! é€™é¡ formula è½‰æ›æˆå¸¶ external è·¯å¾‘èªªæ˜
    """
    c = change.copy()
    c['old_formula'] = pretty_formula(c.get('old_formula'), ref_map)
    c['new_formula'] = pretty_formula(c.get('new_formula'), ref_map)
    return c

current_processing_file = None
processing_start_time = None
force_stop = False
baseline_completed = False

class ActivePollingHandler:
    def __init__(self):
        self.polling_tasks = {}
        self.lock = threading.Lock()
        self.stop_event = threading.Event()

    def start_polling(self, file_path, event_number):
        try:
            file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
        except Exception:
            file_size_mb = 0
        if file_size_mb < POLLING_SIZE_THRESHOLD_MB:
            print(f"[è¼ªè©¢] æª”æ¡ˆ: {os.path.basename(file_path)}ï¼ˆç´°fileï¼Œå¯†é›†è¼ªè©¢ï¼Œæ¯{DENSE_POLLING_INTERVAL_SEC}sï¼Œå…±{DENSE_POLLING_DURATION_SEC}sï¼‰")
            self._start_dense_polling(file_path, event_number)
        else:
            print(f"[è¼ªè©¢] æª”æ¡ˆ: {os.path.basename(file_path)}ï¼ˆå¤§fileï¼Œå†·éœæœŸè¼ªè©¢ï¼Œæ¯{SPARSE_POLLING_INTERVAL_SEC}sï¼‰")
            self._start_sparse_polling(file_path, event_number)

    def _start_dense_polling(self, file_path, event_number):
        with self.lock:
            if file_path in self.polling_tasks:
                self.polling_tasks[file_path]['timer'].cancel()
            def task_wrapper(remaining_duration):
                self._poll_dense(file_path, event_number, remaining_duration)
            timer = threading.Timer(DENSE_POLLING_INTERVAL_SEC, task_wrapper, args=(DENSE_POLLING_DURATION_SEC,))
            self.polling_tasks[file_path] = {'timer': timer, 'remaining_duration': DENSE_POLLING_DURATION_SEC}
            timer.start()
            print(f"    [è¼ªè©¢å•Ÿå‹•] {os.path.basename(file_path)}")

    def _poll_dense(self, file_path, event_number, remaining_duration):
        if self.stop_event.is_set(): return
        print(f"    [è¼ªè©¢å€’æ•¸] {os.path.basename(file_path)}ï¼Œå°šé¤˜: {remaining_duration}s")
        has_changes = compare_excel_changes(file_path, silent=True, event_number=event_number, is_polling=True)
        with self.lock:
            if file_path not in self.polling_tasks: return
            if has_changes:
                self.polling_tasks[file_path]['remaining_duration'] = DENSE_POLLING_DURATION_SEC
            else:
                self.polling_tasks[file_path]['remaining_duration'] -= DENSE_POLLING_INTERVAL_SEC
            new_remaining_duration = self.polling_tasks[file_path]['remaining_duration']
            if new_remaining_duration > 0:
                def task_wrapper(): self._poll_dense(file_path, event_number, new_remaining_duration)
                new_timer = threading.Timer(DENSE_POLLING_INTERVAL_SEC, task_wrapper)
                self.polling_tasks[file_path]['timer'] = new_timer
                new_timer.start()
            else:
                print(f"    [è¼ªè©¢çµæŸ] {os.path.basename(file_path)}")
                self.polling_tasks.pop(file_path, None)

    def _start_sparse_polling(self, file_path, event_number):
        with self.lock:
            if file_path in self.polling_tasks:
                self.polling_tasks[file_path]['timer'].cancel()
            def task_wrapper():
                self._poll_sparse(file_path, event_number)
            timer = threading.Timer(SPARSE_POLLING_INTERVAL_SEC, task_wrapper)
            self.polling_tasks[file_path] = {'timer': timer, 'waiting': True}
            timer.start()
            print(f"    [å†·éœæœŸå•Ÿå‹•] {os.path.basename(file_path)}")

    def _poll_sparse(self, file_path, event_number):
        if self.stop_event.is_set(): return
        print(f"    [å†·éœæœŸæª¢æŸ¥] {os.path.basename(file_path)}")
        has_changes = compare_excel_changes(file_path, silent=True, event_number=event_number, is_polling=True)
        with self.lock:
            if file_path not in self.polling_tasks: return
            if has_changes:
                def task_wrapper():
                    self._poll_sparse(file_path, event_number)
                new_timer = threading.Timer(SPARSE_POLLING_INTERVAL_SEC, task_wrapper)
                self.polling_tasks[file_path]['timer'] = new_timer
                new_timer.start()
            else:
                print(f"    [å†·éœæœŸçµæŸ] {os.path.basename(file_path)}")
                self.polling_tasks.pop(file_path, None)

    def stop(self):
        self.stop_event.set()
        with self.lock:
            for task in self.polling_tasks.values(): task['timer'].cancel()
            self.polling_tasks.clear()

active_polling_handler = ActivePollingHandler()

def signal_handler(signum, frame):
    global force_stop
    if not force_stop:
        force_stop = True
        print("\nğŸ›‘ æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨å®‰å…¨åœæ­¢...")
        if current_processing_file: print(f"   ç›®å‰è™•ç†æª”æ¡ˆ: {current_processing_file}")
        active_polling_handler.stop()
        print("   (å†æŒ‰ä¸€æ¬¡ Ctrl+C å¼·åˆ¶é€€å‡º)")
    else:
        print("\nğŸ’¥ å¼·åˆ¶é€€å‡º...")
        import sys
        sys.exit(1)
signal.signal(signal.SIGINT, signal_handler)

def get_memory_usage():
    try:
        return psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024
    except Exception:
        return 0

def check_memory_limit():
    if not ENABLE_MEMORY_MONITOR: return False
    current_memory = get_memory_usage()
    if current_memory > MEMORY_LIMIT_MB:
        print(f"âš ï¸ è¨˜æ†¶é«”ä½¿ç”¨é‡éé«˜: {current_memory:.1f} MB > {MEMORY_LIMIT_MB} MB")
        print("   æ­£åœ¨åŸ·è¡Œåƒåœ¾å›æ”¶...")
        gc.collect()
        new_memory = get_memory_usage()
        print(f"   åƒåœ¾å›æ”¶å¾Œ: {new_memory:.1f} MB")
        return new_memory > MEMORY_LIMIT_MB
    return False

def save_progress(completed_files, total_files):
    if not ENABLE_RESUME: return
    try:
        progress_data = {"timestamp": datetime.now().isoformat(), "completed": completed_files, "total": total_files}
        with open(RESUME_LOG_FILE, 'w', encoding='utf-8') as f: json.dump(progress_data, f, ensure_ascii=False, indent=2)
    except Exception as e: print(f"[WARN] ç„¡æ³•å„²å­˜é€²åº¦: {e}")

def load_progress():
    if not ENABLE_RESUME or not os.path.exists(RESUME_LOG_FILE): return None
    try:
        with open(RESUME_LOG_FILE, 'r', encoding='utf-8') as f: return json.load(f)
    except Exception as e:
        print(f"[WARN] ç„¡æ³•è¼‰å…¥é€²åº¦: {e}")
        return None

def timeout_handler():
    global current_processing_file, processing_start_time, force_stop, baseline_completed
    while not force_stop and not baseline_completed:
        time.sleep(10)
        if current_processing_file and processing_start_time:
            elapsed = time.time() - processing_start_time
            if elapsed > FILE_TIMEOUT_SECONDS:
                print(f"\nâ° æª”æ¡ˆè™•ç†è¶…æ™‚! (æª”æ¡ˆ: {current_processing_file}, å·²è™•ç†: {elapsed:.1f}s > {FILE_TIMEOUT_SECONDS}s)")
                current_processing_file = None
                processing_start_time = None

def get_all_excel_files(folders):
    all_files = []
    for folder in folders:
        if os.path.isfile(folder):
            if folder.lower().endswith(SUPPORTED_EXTS) and not os.path.basename(folder).startswith('~$'):
                all_files.append(folder)
        elif os.path.isdir(folder):
            for dirpath, _, filenames in os.walk(folder):
                for f in filenames:
                    if f.lower().endswith(SUPPORTED_EXTS) and not f.startswith('~$'):
                        all_files.append(os.path.join(dirpath, f))
    return all_files

def serialize_cell_value(value):
    if value is None: return None
    if isinstance(value, ArrayFormula): return None
    if isinstance(value, datetime): return value.isoformat()
    if isinstance(value, (int, float, str, bool)): return value
    return str(value)

def get_excel_last_author(path):
    try:
        wb = load_workbook(path, read_only=True)
        author = wb.properties.lastModifiedBy
        wb.close(); del wb
        return author
    except Exception: return None

def copy_to_cache(network_path, silent=False):
    if not USE_LOCAL_CACHE: return network_path
    try:
        os.makedirs(CACHE_FOLDER, exist_ok=True)
        if not os.path.exists(network_path): raise FileNotFoundError(f"ç¶²çµ¡æª”æ¡ˆä¸å­˜åœ¨: {network_path}")
        if not os.access(network_path, os.R_OK): raise PermissionError(f"ç„¡æ³•è®€å–ç¶²çµ¡æª”æ¡ˆ: {network_path}")
        file_hash = hashlib.md5(network_path.encode('utf-8')).hexdigest()[:16]
        cache_file = os.path.join(CACHE_FOLDER, f"{file_hash}_{os.path.basename(network_path)}")
        if os.path.exists(cache_file):
            try:
                if os.path.getmtime(cache_file) >= os.path.getmtime(network_path): return cache_file
            except Exception: pass
        network_size = os.path.getsize(network_path)
        if not silent: print(f"   ğŸ“¥ è¤‡è£½åˆ°ç·©å­˜: {os.path.basename(network_path)} ({network_size/(1024*1024):.1f} MB)")
        copy_start = time.time()
        shutil.copy2(network_path, cache_file)
        if not silent: print(f"      è¤‡è£½å®Œæˆï¼Œè€—æ™‚ {time.time() - copy_start:.1f} ç§’")
        return cache_file
    except Exception as e:
        if not silent: print(f"   âŒ ç·©å­˜å¤±æ•—: {e}")
        return network_path

def safe_load_workbook(path, max_retry=5, delay=0.5, **kwargs):
    last_err = None
    for i in range(max_retry):
        try:
            wb = load_workbook(path, **kwargs)
            return wb
        except PermissionError as e:
            last_err = e
            time.sleep(delay)
        except Exception as e:
            last_err = e
            break
    raise last_err

def dump_excel_cells_with_timeout(path, show_sheet_detail=True, silent=False):
    global current_processing_file, processing_start_time
    current_processing_file = path
    processing_start_time = time.time()
    wb = None
    try:
        if not silent: print(f"   ğŸ“Š æª”æ¡ˆå¤§å°: {os.path.getsize(path)/(1024*1024):.1f} MB")
        local_path = copy_to_cache(path, silent=silent)
        # è¤‡è£½å®Œ sleep ä¸€ä¸‹ï¼Œæ¸›race condition
        time.sleep(0.2)
        read_only_mode = True
        if not silent: print(f"   ğŸš€ è®€å–æ¨¡å¼: read_only={read_only_mode}, data_only=False")
        wb = safe_load_workbook(local_path, read_only=read_only_mode, data_only=False)
        result = {}
        worksheet_count = len(wb.worksheets)
        if not silent and show_sheet_detail: print(f"   ğŸ“‹ å·¥ä½œè¡¨æ•¸é‡: {worksheet_count}")
        for idx, ws in enumerate(wb.worksheets, 1):
            cell_count = 0
            ws_data = {}
            if ws.max_row > 1 or ws.max_column > 1:
                for row in ws.iter_rows():
                    for cell in row:
                        fstr = get_cell_formula(cell)
                        vstr = serialize_cell_value(cell.value)
                        if fstr is not None or vstr is not None:
                            ws_data[cell.coordinate] = {"formula": fstr, "value": vstr}
                            cell_count += 1
            if show_sheet_detail and not silent: print(f"      è™•ç†å·¥ä½œè¡¨ {idx}/{worksheet_count}: {ws.title}ï¼ˆ{cell_count} æœ‰è³‡æ–™ cellï¼‰")
            if ws_data: result[ws.title] = ws_data
        wb.close(); wb = None
        if not silent and show_sheet_detail: print(f"   âœ… Excel è®€å–å®Œæˆ")
        return result
    except Exception as e:
        if not silent: print(f"   âŒ Excel è®€å–å¤±æ•—: {e}")
        return None
    finally:
        if wb: wb.close(); del wb
        current_processing_file = None
        processing_start_time = None
        
def hash_excel_content(cells_dict):
    if cells_dict is None: return None
    try:
        content_str = json.dumps(cells_dict, sort_keys=True, ensure_ascii=False)
        return hashlib.md5(content_str.encode('utf-8')).hexdigest()
    except Exception: return None

def baseline_file_path(base_name):
    return os.path.join(LOG_FOLDER, f"{base_name}.baseline.json.gz")

def load_baseline(baseline_file):
    try:
        if os.path.exists(baseline_file):
            with gzip.open(baseline_file, 'rt', encoding='utf-8') as f:
                return json.load(f)
        return None
    except Exception as e:
        print(f"[ERROR][load_baseline] {baseline_file}: {e}")
        return None

def save_baseline(baseline_file, data):
    dir_name = os.path.dirname(baseline_file)
    os.makedirs(dir_name, exist_ok=True)
    fd, tmp_path = tempfile.mkstemp(suffix='.tmp', prefix='baseline_', dir=dir_name)
    os.close(fd)
    try:
        with gzip.open(tmp_path, 'wt', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, separators=(',', ':'))
        with gzip.open(tmp_path, 'rt', encoding='utf-8') as f: _ = json.load(f)
        os.replace(tmp_path, baseline_file)
        return True
    except Exception as e:
        print(f"[ERROR][save_baseline] error saving {baseline_file}: {e}")
        if os.path.exists(tmp_path): os.remove(tmp_path)
        return False

def is_force_baseline_file(filepath):
    try:
        for pattern in FORCE_BASELINE_ON_FIRST_SEEN:
            if pattern.lower() in filepath.lower(): return True
        return False
    except Exception: return False

def human_readable_size(num_bytes):
    if num_bytes is None: return "0 B"
    for unit in ['B','KB','MB','GB','TB']:
        if num_bytes < 1024.0: return f"{num_bytes:,.2f} {unit}"
        num_bytes /= 1024.0
    return f"{num_bytes:.2f} PB"

def create_baseline_for_files_robust(xlsx_files, skip_force_baseline=True):
    global force_stop, baseline_completed
    total = len(xlsx_files)
    if total == 0:
        print("[INFO] æ²’æœ‰éœ€è¦ baseline çš„æª”æ¡ˆã€‚")
        baseline_completed = True
        return
    print("\n" + "="*90 + "\n" + " BASELINE å»ºç«‹ç¨‹åº ".center(90, "=") + "\n" + "="*90)
    progress = load_progress()
    start_index = 0
    if progress and ENABLE_RESUME:
        print(f"ğŸ”„ ç™¼ç¾ä¹‹å‰çš„é€²åº¦è¨˜éŒ„: å®Œæˆ {progress.get('completed', 0)}/{progress.get('total', 0)}")
        if input("æ˜¯å¦è¦å¾ä¸Šæ¬¡ä¸­æ–·çš„åœ°æ–¹ç¹¼çºŒ? (y/n): ").strip().lower() == 'y':
            start_index = progress.get('completed', 0)
    if ENABLE_TIMEOUT:
        timeout_thread = threading.Thread(target=timeout_handler, daemon=True); timeout_thread.start()
        print(f"â° å•Ÿç”¨è¶…æ™‚ä¿è­·: {FILE_TIMEOUT_SECONDS} ç§’")
    if ENABLE_MEMORY_MONITOR: print(f"ğŸ’¾ å•Ÿç”¨è¨˜æ†¶é«”ç›£æ§: {MEMORY_LIMIT_MB} MB")
    print(f"ğŸš€ å•Ÿç”¨å„ªåŒ–: {[opt for flag, opt in [(USE_LOCAL_CACHE, 'æœ¬åœ°ç·©å­˜'), (ENABLE_FAST_MODE, 'å¿«é€Ÿæ¨¡å¼')] if flag]}")
    print(f"ğŸ“‚ Baseline å„²å­˜ä½ç½®: {os.path.abspath(LOG_FOLDER)}")
    if USE_LOCAL_CACHE: print(f"ğŸ’¾ æœ¬åœ°ç·©å­˜ä½ç½®: {os.path.abspath(CACHE_FOLDER)}")
    print(f"ğŸ“‹ è¦è™•ç†çš„æª”æ¡ˆ: {total} å€‹ (å¾ç¬¬ {start_index + 1} å€‹é–‹å§‹)")
    print(f"â° é–‹å§‹æ™‚é–“: {datetime.now():%Y-%m-%d %H:%M:%S}\n" + "-"*90)
    os.makedirs(LOG_FOLDER, exist_ok=True)
    if USE_LOCAL_CACHE: os.makedirs(CACHE_FOLDER, exist_ok=True)
    
    success_count, skip_count, error_count = 0, 0, 0
    start_time = time.time()
    for i in range(start_index, total):
        if force_stop:
            print("\nğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡è™Ÿï¼Œæ­£åœ¨å®‰å…¨é€€å‡º..."); save_progress(i, total); break
        
        file_path = xlsx_files[i]
        base_name = os.path.basename(file_path)
        
        if check_memory_limit():
            print(f"âš ï¸ è¨˜æ†¶é«”ä½¿ç”¨é‡éé«˜ï¼Œæš«åœ10ç§’..."); time.sleep(10)
            if check_memory_limit(): print(f"âŒ è¨˜æ†¶é«”ä»ç„¶éé«˜ï¼Œåœæ­¢è™•ç†"); save_progress(i, total); break

        file_start_time = time.time()
        print(f"[{i+1:>2}/{total}] è™•ç†ä¸­: {base_name} (è¨˜æ†¶é«”: {get_memory_usage():.1f}MB)")
        cell_data = None
        try:
            baseline_file = baseline_file_path(base_name)
            old_baseline = load_baseline(baseline_file)
            old_hash = old_baseline['content_hash'] if old_baseline and 'content_hash' in old_baseline else None
            
            cell_data = dump_excel_cells_with_timeout(file_path)
            
            if cell_data is None:
                if current_processing_file is None and (time.time() - file_start_time) > FILE_TIMEOUT_SECONDS:
                     print(f"  çµæœ: [TIMEOUT]")
                else:
                     print(f"  çµæœ: [READ_ERROR]")
                error_count += 1
            else:
                curr_hash = hash_excel_content(cell_data)
                if old_hash == curr_hash and old_hash is not None:
                    print(f"  çµæœ: [SKIP] (Hash unchanged)"); skip_count += 1
                else:
                    curr_author = get_excel_last_author(file_path)
                    if save_baseline(baseline_file, {"last_author": curr_author, "content_hash": curr_hash, "cells": cell_data}):
                        print(f"  çµæœ: [OK]")
                        print(f"  Baseline: {os.path.basename(baseline_file)}")
                        success_count += 1
                    else:
                        print(f"  çµæœ: [SAVE_ERROR]"); error_count += 1
            
            print(f"  è€—æ™‚: {time.time() - file_start_time:.2f} ç§’\n")
            save_progress(i + 1, total)
        except Exception as e:
            print(f"  çµæœ: [UNEXPECTED_ERROR]\n  éŒ¯èª¤: {e}\n  è€—æ™‚: {time.time() - file_start_time:.2f} ç§’\n"); error_count += 1
            save_progress(i + 1, total)
        finally:
            if cell_data is not None: del cell_data
            if 'old_baseline' in locals() and old_baseline is not None: del old_baseline
            gc.collect()

    baseline_completed = True
    print("-" * 90 + f"\nğŸ¯ BASELINE å»ºç«‹å®Œæˆ! (ç¸½è€—æ™‚: {time.time() - start_time:.2f} ç§’)")
    print(f"âœ… æˆåŠŸ: {success_count}, â­ï¸  è·³é: {skip_count}, âŒ å¤±æ•—: {error_count}")
    if ENABLE_RESUME and os.path.exists(RESUME_LOG_FILE):
        try: os.remove(RESUME_LOG_FILE); print(f"ğŸ§¹ æ¸…ç†é€²åº¦æª”æ¡ˆ")
        except Exception: pass
    print("\n" + "=" * 90 + "\n")

def get_file_mtime(filepath):
    try:
        return datetime.fromtimestamp(os.path.getmtime(filepath)).strftime("%Y-%m-%d %H:%M:%S")
    except Exception:
        return "Unknown"

def compare_excel_changes(file_path, silent=True, event_number=None, is_polling=False):
    old_baseline, curr_cells, changes = None, None, None
    has_changes = False
    try:
        base_name = os.path.basename(file_path)
        baseline_file = baseline_file_path(base_name)
        old_baseline = load_baseline(baseline_file)
        
        if not old_baseline:
            if not silent: print(f"[INFO] æ²’æœ‰ baseline: {base_name}ï¼Œå»ºç«‹æ–° baseline...")
            cell_data = dump_excel_cells_with_timeout(file_path, show_sheet_detail=True, silent=silent)
            if cell_data is None: return False
            curr_author = get_excel_last_author(file_path)
            curr_hash = hash_excel_content(cell_data)
            if save_baseline(baseline_file, {"last_author": curr_author, "content_hash": curr_hash, "cells": cell_data}):
                print(f"  Baseline: {os.path.basename(baseline_file)}")
            del cell_data
            return True

        curr_cells = dump_excel_cells_with_timeout(file_path, show_sheet_detail=False, silent=silent)
        
        if curr_cells is None:
            print(f"[ERROR] è®€å–æª”æ¡ˆå¤±æ•—ï¼Œç„¡æ³•æ¯”è¼ƒ: {base_name}")
            return False
            
        curr_hash = hash_excel_content(curr_cells)
        old_hash = old_baseline.get('content_hash')
        
        if curr_hash == old_hash:
            if not silent and not is_polling: print(f"[INFO] æª”æ¡ˆç„¡è®Šæ›´: {base_name}")
            return False
            
        has_changes = True
        curr_author = get_excel_last_author(file_path)
        
        if event_number is not None and not is_polling:
            print("\n" + "="*50 + f"\nğŸŸ¢ [äº‹ä»¶ #{event_number}] {datetime.now():%Y-%m-%d %H:%M:%S}")
        
        print(f"ğŸš¨ [æª”æ¡ˆæœ‰è®Šæ›´] {base_name}")
        print(f"  ä½œè€…: {old_baseline.get('last_author', 'N/A')} â†’ {curr_author or 'N/A'}")
        
        old_h_str = f"{old_hash[:8]}..." if old_hash else "N/A"
        new_h_str = f"{curr_hash[:8]}..." if curr_hash else "N/A"
        print(f"  Hash: {old_h_str} â†’ {new_h_str}")
        
        changes = []
        old_cells = old_baseline.get('cells', {})
        all_ws_names = set(old_cells.keys()) | set(curr_cells.keys())
        for ws_name in all_ws_names:
            old_ws_cells, curr_ws_cells = old_cells.get(ws_name, {}), curr_cells.get(ws_name, {})
            all_coords = set(old_ws_cells.keys()) | set(curr_ws_cells.keys())
            for cell_coord in all_coords:
                old_cell = old_ws_cells.get(cell_coord, {"formula": None, "value": None})
                curr_cell = curr_ws_cells.get(cell_coord, {"formula": None, "value": None})
                # å””åŒæ™‚å ±å…¬å¼åŒvalueï¼šå¦‚æœformulaæœ‰è®Šåªå ±å…¬å¼ï¼Œå¦å‰‡åªå ±value
                if old_cell['formula'] != curr_cell['formula']:
                    changes.append({'worksheet': ws_name, 'cell': cell_coord,
                                    'old_formula': old_cell['formula'], 'new_formula': curr_cell['formula'],
                                    'old_value': None, 'new_value': None})
                elif str(old_cell['value']) != str(curr_cell['value']):
                    changes.append({'worksheet': ws_name, 'cell': cell_coord,
                                    'old_formula': None, 'new_formula': None,
                                    'old_value': old_cell['value'], 'new_value': curr_cell['value']})

        ref_map = extract_external_refs(file_path)
        filtered_changes = [enrich_formula_external_path(c, ref_map) for c in changes]
        
        if not filtered_changes:
            if not is_polling: print("  [INFO] å…§å®¹æœ‰è®Šæ›´ï¼Œä½†éæ¿¾å¾Œç„¡é¡¯è‘—å·®ç•°ã€‚")
            save_baseline(baseline_file, {"last_author": curr_author, "content_hash": curr_hash, "cells": curr_cells})
            return True

        # === æ–°å¢ï¼šæº–å‚™ file_infoï¼Œå‚³å» print_cell_changes_summary ===
        baseline_mtime = get_file_mtime(baseline_file)         # baseline file çš„ last modified
        current_mtime = get_file_mtime(file_path)              # current file çš„ last modified

        file_info = {
            'filename': os.path.basename(file_path),
            'baseline_time': baseline_mtime,
            'current_time': current_mtime
        }

        print_cell_changes_summary(filtered_changes, file_info)
        log_changes_to_csv(file_path, curr_author, filtered_changes)
        save_baseline(baseline_file, {"last_author": curr_author, "content_hash": curr_hash, "cells": curr_cells})
        return True
    except Exception as e:
        print(f"[ERROR] æ¯”è¼ƒæª”æ¡ˆå¤±æ•—: {file_path} - {e}")
        import traceback; traceback.print_exc()
        return False
    finally:
        if old_baseline: del old_baseline
        if curr_cells: del curr_cells
        if changes: del changes
        gc.collect()

recent_events = {}

def is_duplicate_event(file_path, interval=DEBOUNCE_INTERVAL_SEC):
    now = time.time()
    last = recent_events.get(file_path, 0)
    recent_events[file_path] = now
    return (now - last) < interval

class ExcelChangeHandler(FileSystemEventHandler):
    def on_modified(self, event):
        if not event.is_directory and event.src_path.lower().endswith(SUPPORTED_EXTS):
            # éæ¿¾æš«å­˜æ–‡ä»¶
            if os.path.basename(event.src_path).startswith('~$'):
                return
            if is_duplicate_event(event.src_path):
                return
            print(f"[EVENT] æª”æ¡ˆä¿®æ”¹: {event.src_path}")
            compare_excel_changes(event.src_path, silent=False, event_number=None, is_polling=False)
            active_polling_handler.start_polling(event.src_path, event_number=None)

    def on_created(self, event):
        if not event.is_directory and event.src_path.lower().endswith(SUPPORTED_EXTS):
            # éæ¿¾æš«å­˜æ–‡ä»¶
            if os.path.basename(event.src_path).startswith('~$'):
                return
            if is_duplicate_event(event.src_path):
                return
            print(f"[EVENT] æª”æ¡ˆæ–°å»º: {event.src_path}")
            compare_excel_changes(event.src_path, silent=False, event_number=None, is_polling=False)
            active_polling_handler.start_polling(event.src_path, event_number=None)

    def on_moved(self, event):
        if not event.is_directory and event.dest_path.lower().endswith(SUPPORTED_EXTS):
            # éæ¿¾æš«å­˜æ–‡ä»¶
            if os.path.basename(event.dest_path).startswith('~$'):
                return
            if is_duplicate_event(event.dest_path):
                return
            print(f"[EVENT] æª”æ¡ˆç§»å‹•/é‡å‘½å (å¯èƒ½æ˜¯ Excel ä¿å­˜æ“ä½œ): {event.dest_path}")
            compare_excel_changes(event.dest_path, silent=False, event_number=None, is_polling=False)
            active_polling_handler.start_polling(event.dest_path, event_number=None)

    def on_deleted(self, event):
        if not event.is_directory and event.src_path.lower().endswith(SUPPORTED_EXTS):
            # éæ¿¾æš«å­˜æ–‡ä»¶
            if os.path.basename(event.src_path).startswith('~$'):
                return
            if is_duplicate_event(event.src_path):
                return
            print(f"[EVENT] æª”æ¡ˆåˆªé™¤: {event.src_path}")

def start_watchdog_monitor():
    global force_stop
    force_stop = False
    print("\n" + "="*80 + "\n" + " å•Ÿå‹• Excel æª”æ¡ˆç›£æ§ ".center(80, "=") + "\n" + "="*80)
    valid_folders = [folder for folder in WATCH_FOLDERS if os.path.exists(folder)]
    if not valid_folders:
        print("âŒ æ²’æœ‰æœ‰æ•ˆçš„ç›£æ§è³‡æ–™å¤¾ï¼Œç„¡æ³•å•Ÿå‹•ç›£æ§"); return
    print("  ç›£æ§è³‡æ–™å¤¾:")
    for folder in valid_folders: print(f"    ğŸ“‚ {folder}")
    print(f"\n  æ”¯æ´æª”æ¡ˆ: {SUPPORTED_EXTS}\n  è®Šæ›´è¨˜éŒ„: {CSV_LOG_FILE}")
    
    event_handler = ExcelChangeHandler()
    observer = Observer()
    for folder in valid_folders:
        observer.schedule(event_handler, folder, recursive=True)
    
    print("\nğŸ” ç›£æ§ä¸­... (æŒ‰ Ctrl+C åœæ­¢)\n" + "-"*80)
    observer.start()
    try:
        while not force_stop: time.sleep(1)
    except KeyboardInterrupt:
        print("\nğŸ›‘ æ”¶åˆ° Ctrl+C åœæ­¢ä¿¡è™Ÿ...")
    finally:
        active_polling_handler.stop()
        observer.stop()
        observer.join()
        print("ğŸ“„ ç›£æ§å·²åœæ­¢")

# ========= æ–°å¢ï¼šExcel cell changes summary print =========
def print_cell_changes_summary(filtered_changes, file_info=None):
    """
    æ ¹æ“š worksheet åˆ†çµ„ï¼Œåˆ†é–‹é¡¯ç¤ºæ¯å¼µå·¥ä½œè¡¨çš„ diff table
    """
    if not filtered_changes:
        print("  [INFO] ç„¡é¡¯è‘— cell è®Šæ›´")
        return

    print(f"  [SUMMARY] æœ‰ {len(filtered_changes)} å€‹ cell æœ‰æ”¹å‹•ï¼š")
    # --- æ ¹æ“š worksheet åˆ†çµ„ ---
    ws_groups = {}
    for c in filtered_changes:
        ws = c.get('worksheet', 'N/A')
        ws_groups.setdefault(ws, []).append(c)

    # --- æ¯å€‹ worksheet ä¸€å€‹è¡¨æ ¼ ---
    for ws_name, ws_changes in ws_groups.items():
        # æº–å‚™æ•¸æ“š
        old_data = {}
        new_data = {}
        for c in ws_changes:
            cell = c.get('cell', 'N/A')
            key = cell  # åªé¡¯ç¤º cell addressï¼ˆå””å†åŠ  worksheet åï¼‰
            old_f = c.get('old_formula')
            new_f = c.get('new_formula')
            old_v = c.get('old_value')
            new_v = c.get('new_value')
            if old_f is not None or new_f is not None:
                old_data[key] = old_f
                new_data[key] = new_f
            else:
                old_data[key] = old_v
                new_data[key] = new_v

        # çµ„åˆä¸€å€‹å°ˆå±¬ file_info çµ¦æ¯å€‹ worksheet è¡¨é ­åŠ åŸ‹ worksheet å
        if file_info:
            ws_file_info = dict(file_info)  # è¤‡è£½ä¸€ä»½
            ws_file_info['worksheet'] = ws_name
        else:
            ws_file_info = {'worksheet': ws_name}

        # æš«æ™‚é—œé–‰æ™‚é–“æˆ³è¨˜é¡¯ç¤º
        global _original_print
        builtins.print = _original_print

        print_aligned_console_diff(old_data, new_data, ws_file_info)

        # æ¢å¾©æ™‚é–“æˆ³è¨˜é¡¯ç¤º
        builtins.print = timestamped_print

# ========= æ–°å¢ï¼šExcel cell changes logging =========
def log_changes_to_csv(file_path, author, filtered_changes):
    if not filtered_changes: return
    os.makedirs(os.path.dirname(CSV_LOG_FILE), exist_ok=True)
    try:
        with gzip.open(CSV_LOG_FILE, 'at', encoding='utf-8') as f:
            writer = csv.writer(f)
            for c in filtered_changes:
                ws = c.get('worksheet', '')
                cell = c.get('cell', '')
                old_f = c.get('old_formula', '')
                new_f = c.get('new_formula', '')
                old_v = c.get('old_value', '')
                new_v = c.get('new_value', '')
                # å„²å­˜åœ¨log fileå…¥é¢ï¼Œå…©è€…éƒ½è¦æœ‰
                writer.writerow([
                    datetime.now().isoformat(),
                    os.path.basename(file_path),
                    author or '',
                    ws, cell,
                    old_f, new_f,
                    old_v, new_v
                ])
    except Exception as e:
        print(f"[ERROR] log_changes_to_csv: {e}")

def print_console_header():
    print("\n" + "="*80 + "\n" + " Excel File Change Watcher (è¨ºæ–·å¼·åŒ–ç‰ˆæœ¬) ".center(80, "-") + "\n" + "="*80)
    print(f"  ç›®å‰ä½¿ç”¨è€…: {os.getlogin()}")

if __name__ == "__main__":
    try:
        print_console_header()
        os.makedirs(LOG_FOLDER, exist_ok=True)
        if USE_LOCAL_CACHE: os.makedirs(CACHE_FOLDER, exist_ok=True)
        
        if SCAN_ALL_MODE:
            all_files = get_all_excel_files(WATCH_FOLDERS)
            print(f"ç¸½å…±æ‰¾åˆ° {len(all_files)} å€‹ Excel æª”æ¡ˆã€‚")
            create_baseline_for_files_robust(all_files, skip_force_baseline=True)
        else:
            target_files = get_all_excel_files(MANUAL_BASELINE_TARGET)
            print(f"æ‰‹å‹•æŒ‡å®š baselineï¼Œåˆå…± {len(target_files)} å€‹ Excel æª”æ¡ˆã€‚")
            create_baseline_for_files_robust(target_files, skip_force_baseline=False)
        
        if force_stop:
            print("ğŸ›‘ ç¨‹åºåœ¨ baseline éšæ®µè¢«ä¸­æ–·ï¼Œé€€å‡º...")
        else:
            start_watchdog_monitor()
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç¨‹åºè¢«ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"\n[CRITICAL ERROR][main] ç¨‹å¼ä¸»æµç¨‹ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}")
        import traceback; traceback.print_exc()
    finally:
        print("\nç¨‹åºçµæŸã€‚")
