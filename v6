# -*- coding: utf-8 -*-
"""
è€Œå®¶å€‹ç¨‹å¼é‡åˆ°d array function ä½¢ä¿‚print èƒŒå¾Œmemory address æ—¢è®Šå‹•
ä½†user é—œå¿ƒæ—¢ä¿‚æ¢function ç”¨æ—¢å­—çœ¼æœ‰ç„¡è®Šå‹•

å¦å¤–æœ‰d case user edit ä¸€d cell æœƒå½±éŸ¿æˆå¼µworksheet é‡æ–°è¨ˆç®—
ä»¤åˆ°d cell value è®Šæ™’
ä½†å‘¢d cell æ—¢èƒŒå¾Œå…¶å¯¦æ¢formula ç„¡è®Šåˆ°
å’æ¨£å””æ‡‰è©²è¨ˆåšå€‹change
å› ç‚ºuser å…¶å¯¦ç„¡edit åˆ°å…¶ä»–cell
Created on Fri Jul 11 17:49:32 2025

@author: kccheng
"""

import os
import time
import csv
import hashlib
import gc
import psutil
import shutil
import gzip
import json
import signal
import threading
import tempfile
import re
import zipfile
import xml.etree.ElementTree as ET
from datetime import datetime
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from openpyxl import load_workbook
from openpyxl.worksheet.formula import ArrayFormula
import builtins
from io import StringIO

# ============ PATCH: Override print for timestamping ============
_original_print = builtins.print

def timestamped_print(*args, **kwargs):
    """Overrides the default print function to add a timestamp to each line."""
    output_buffer = StringIO()
    _original_print(*args, file=output_buffer, **kwargs)
    message = output_buffer.getvalue()
    output_buffer.close()

    if not message.strip():
        _original_print(message, end='')
        return

    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    lines = message.rstrip().split('\n')
    # Handle empty lines from something like print("\n" + "="*50)
    # We want to timestamp the line with the equals signs, not the blank line before it.
    if lines and not lines[0]:
        _original_print(f"[{timestamp}]") # Print timestamp for the blank line
        lines = lines[1:] # Process the rest of the lines

    timestamped_message = '\n'.join(f"[{timestamp}] {line}" for line in lines if line)
    
    _original_print(timestamped_message)

builtins.print = timestamped_print
# ============ END PATCH ============

def extract_external_refs(xlsx_path):
    """ è§£æ Excel xlsx ä¸­ external reference mapping: [n] -> è·¯å¾‘ """
    ref_map = {}
    try:
        with zipfile.ZipFile(xlsx_path, 'r') as z:
            rels = ET.fromstring(z.read('xl/_rels/workbook.xml.rels'))
            for rel in rels.findall('{http://schemas.openxmlformats.org/package/2006/relationships}Relationship'):
                if rel.attrib['Type'].endswith('/externalLink'):
                    target = rel.attrib['Target']
                    m = re.search(r'externalLink(\d+)\.xml', target)
                    if m:
                        num = int(m.group(1))
                        try:
                            link_xml = z.read(f'xl/{target}')
                            link_tree = ET.fromstring(link_xml)
                            book_elem = link_tree.find('.//{http://schemas.openxmlformats.org/spreadsheetml/2006/main}externalBookPr')
                            if book_elem is not None:
                                path = book_elem.attrib.get('href', '')
                            else:
                                path = ''
                            ref_map[num] = path
                        except Exception:
                            ref_map[num] = ''
    except Exception:
        pass
    return ref_map

def pretty_formula(formula, ref_map=None):
    """ é¡¯ç¤º formula æ™‚ï¼Œå¦‚æœæœ‰ [n]Table! é€™ç¨® external workbook referenceï¼Œæœƒé¡¯ç¤ºä¾†æºè·¯å¾‘ """
    if formula is None:
        return None
    
    # ä¿®æ”¹ï¼šè™•ç† ArrayFormula ç‰©ä»¶
    if isinstance(formula, ArrayFormula):
        formula_str = formula.text if hasattr(formula, 'text') else str(formula)
    else:
        formula_str = str(formula)
    
    if ref_map:
        def repl(m):
            n = int(m.group(1))
            path = ref_map.get(n, '')
            if path:
                return f"[å¤–éƒ¨æª”æ¡ˆ{n}: {path}]{m.group(0)}"
            else:
                return m.group(0)
        return re.sub(r'\[(\d+)\][A-Za-z0-9_]+!', repl, formula_str)
    else:
        return formula_str

def get_cell_formula(cell):
    """
    å–å¾— cell å…¬å¼ï¼ˆä¸è«–ä¿‚æ™®é€š formula or array formulaï¼‰ï¼Œä¸€å¾‹å›å‚³å…¬å¼å­—ä¸²
    """
    if cell.data_type == 'f':
        if isinstance(cell.value, ArrayFormula):
            # ä¿®æ”¹ï¼šè¿”å› ArrayFormula çš„å¯¦éš›å…¬å¼å­—ç¬¦ä¸²ï¼Œè€Œä¸æ˜¯ç‰©ä»¶
            return cell.value.text if hasattr(cell.value, 'text') else str(cell.value)
        return cell.value
    return None

def should_filter_change(change, formula_only_mode=True):
    """
    åˆ¤æ–·æ˜¯å¦è¦éæ¿¾é€™å€‹è®Šæ›´
    formula_only_mode: å¦‚æœç‚º Trueï¼Œåªæœ‰å…¬å¼è®ŠåŒ–æ‰ç®—è®Šæ›´ï¼Œå€¼è®ŠåŒ–ä¸ç®—
    """
    old_f, new_f = change.get('old_formula'), change.get('new_formula')
    old_v, new_v = change.get('old_value'), change.get('new_value')
    
    # å¦‚æœæ˜¯ formula_only_modeï¼Œåªçœ‹å…¬å¼è®ŠåŒ–
    if formula_only_mode:
        # æ¨™æº–åŒ–å…¬å¼å­—ç¬¦ä¸²æ¯”è¼ƒ
        old_f_str = str(old_f) if old_f is not None else None
        new_f_str = str(new_f) if new_f is not None else None
        
        # å¦‚æœå…¬å¼æ²’è®Šï¼Œå°±éæ¿¾æ‰
        if old_f_str == new_f_str:
            return True
        
        # å¦‚æœå…©é‚Šéƒ½æ²’æœ‰å…¬å¼ï¼Œä½†å€¼æœ‰è®ŠåŒ–ï¼Œä¹Ÿéæ¿¾æ‰ï¼ˆé€™æ˜¯é‡æ–°è¨ˆç®—å°è‡´çš„ï¼‰
        if old_f_str is None and new_f_str is None:
            return True
            
        return False
    else:
        # åŸä¾†çš„é‚è¼¯ï¼šå…¬å¼å’Œå€¼éƒ½æ²’è®Šæ‰éæ¿¾
        return old_f == new_f and str(old_v) == str(new_v)


def is_array_formula_obj(val):
    """
    åˆ¤æ–·æ˜¯å¦ openpyxl ArrayFormula ç‰©ä»¶
    """
    return isinstance(val, ArrayFormula)

def filter_array_formula_change(change):
    """
    å°æ–¼ formula èˆŠæ–°éƒ½ä¿‚ Noneï¼ˆç„¡å…¬å¼ï¼‰ï¼Œæˆ–è€… formula string å®Œå…¨ç›¸åŒï¼Œå°±å””éœ€è¦é¡¯ç¤º
    åªè¦ formula string æœ‰è®Šï¼Œå””ç†ä¿‚å’ª array formulaï¼Œéƒ½é¡¯ç¤º
    """
    old_f, new_f = change.get('old_formula'), change.get('new_formula')
    if old_f == new_f:
        return True
    return False

def enrich_formula_external_path(change, ref_map):
    """
    å°‡ [n]Table! é€™é¡ formula è½‰æ›æˆå¸¶ external è·¯å¾‘èªªæ˜
    """
    c = change.copy()
    c['old_formula'] = pretty_formula(c.get('old_formula'), ref_map)
    c['new_formula'] = pretty_formula(c.get('new_formula'), ref_map)
    return c

# =========== User Config ============
SCAN_ALL_MODE = True
USE_LOCAL_CACHE = True
CACHE_FOLDER = r"D:\Pzone\watchdog\cache_folder"
ENABLE_FAST_MODE = True
ENABLE_TIMEOUT = True
FILE_TIMEOUT_SECONDS = 120
ENABLE_MEMORY_MONITOR = True
MEMORY_LIMIT_MB = 2048
ENABLE_RESUME = True
FORMULA_ONLY_MODE = True
RESUME_LOG_FILE = r"D:\Pzone\watchdog\\resume_log\baseline_progress.log"
WATCH_FOLDERS = [
    r"V:\MD9\Current\2024\1_Rehearsal (2025.08.01)",
    r"V:\MD9\Constant (T-1 base)\2025Q2\Ballpark\2025.07.08",
    r"V:\MD9\Constant (T-1 base)\2025Q1\Revised\2025.07.18",
    r"X:\4 Pillars\Trial estimates for 2024\Crude_v1"
]
MANUAL_BASELINE_TARGET = []
LOG_FOLDER = r"D:\Pzone\watchdog\log_folder"
LOG_FILE_DATE = datetime.now().strftime('%Y%m%d')
CSV_LOG_FILE = os.path.join(LOG_FOLDER, f"excel_change_log_{LOG_FILE_DATE}.csv.gz")
SUPPORTED_EXTS = ('.xlsx', '.xlsm')
MAX_RETRY = 10
RETRY_INTERVAL_SEC = 2
USE_TEMP_COPY = True
WHITELIST_USERS = ['ckcm0210', 'yourwhiteuser']
LOG_WHITELIST_USER_CHANGE = True
FORCE_BASELINE_ON_FIRST_SEEN = [
    r"\\network_drive\\your_folder1\\must_first_baseline.xlsx",
    "force_this_file.xlsx"
]
# =========== End User Config ============

current_processing_file = None
processing_start_time = None
force_stop = False
baseline_completed = False

class ActivePollingHandler:
    def __init__(self, interval=5, duration=15):
        self.polling_tasks = {}
        self.lock = threading.Lock()
        self.interval = interval
        self.duration = duration
        self.stop_event = threading.Event()

    def start_polling(self, file_path, event_number):
        with self.lock:
            if file_path in self.polling_tasks:
                self.polling_tasks[file_path]['timer'].cancel()
            
            def task_wrapper():
                self.poll_file(file_path, event_number, self.duration)

            timer = threading.Timer(self.interval, task_wrapper)
            self.polling_tasks[file_path] = {'timer': timer, 'remaining_duration': self.duration}
            timer.start()
            print(f"   [è¼ªè©¢å•Ÿå‹•] é–‹å§‹ä¸»å‹•æª¢æŸ¥æª”æ¡ˆ: {os.path.basename(file_path)}")

    def poll_file(self, file_path, event_number, remaining_duration):
        if self.stop_event.is_set(): return

        print(f"   [è¼ªè©¢æª¢æŸ¥] ä¸»å‹•æª¢æŸ¥: {os.path.basename(file_path)} (å‰©é¤˜æª¢æŸ¥æ™‚é–“: {remaining_duration}s)")
        
        has_changes = compare_excel_changes(file_path, silent=False, event_number=event_number, is_polling=True)
        
        with self.lock:
            if file_path not in self.polling_tasks: return

            if has_changes:
                print(f"   [è¼ªè©¢é‡ç½®] åµæ¸¬åˆ°æ–°è®Šæ›´ï¼Œé‡ç½®æª¢æŸ¥è¨ˆæ™‚å™¨ã€‚")
                self.polling_tasks[file_path]['remaining_duration'] = self.duration
            else:
                self.polling_tasks[file_path]['remaining_duration'] -= self.interval

            new_remaining_duration = self.polling_tasks[file_path]['remaining_duration']
            
            if new_remaining_duration > 0:
                def task_wrapper(): self.poll_file(file_path, event_number, new_remaining_duration)
                new_timer = threading.Timer(self.interval, task_wrapper)
                self.polling_tasks[file_path]['timer'] = new_timer
                new_timer.start()
            else:
                print(f"   [è¼ªè©¢çµæŸ] åœ¨éå» {self.duration} ç§’å…§ç„¡æ–°è®Šæ›´ï¼Œåœæ­¢ä¸»å‹•æª¢æŸ¥: {os.path.basename(file_path)}")
                self.polling_tasks.pop(file_path, None)

    def stop(self):
        self.stop_event.set()
        with self.lock:
            for task in self.polling_tasks.values(): task['timer'].cancel()
            self.polling_tasks.clear()

active_polling_handler = ActivePollingHandler()

def signal_handler(signum, frame):
    global force_stop
    if not force_stop:
        force_stop = True
        print("\nğŸ›‘ æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨å®‰å…¨åœæ­¢...")
        if current_processing_file: print(f"   ç›®å‰è™•ç†æª”æ¡ˆ: {current_processing_file}")
        active_polling_handler.stop()
        print("   (å†æŒ‰ä¸€æ¬¡ Ctrl+C å¼·åˆ¶é€€å‡º)")
    else:
        print("\nğŸ’¥ å¼·åˆ¶é€€å‡º...")
        import sys
        sys.exit(1)
signal.signal(signal.SIGINT, signal_handler)

def get_memory_usage():
    try:
        return psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024
    except Exception:
        return 0

def check_memory_limit():
    if not ENABLE_MEMORY_MONITOR: return False
    current_memory = get_memory_usage()
    if current_memory > MEMORY_LIMIT_MB:
        print(f"âš ï¸ è¨˜æ†¶é«”ä½¿ç”¨é‡éé«˜: {current_memory:.1f} MB > {MEMORY_LIMIT_MB} MB")
        print("   æ­£åœ¨åŸ·è¡Œåƒåœ¾å›æ”¶...")
        gc.collect()
        new_memory = get_memory_usage()
        print(f"   åƒåœ¾å›æ”¶å¾Œ: {new_memory:.1f} MB")
        return new_memory > MEMORY_LIMIT_MB
    return False

def save_progress(completed_files, total_files):
    if not ENABLE_RESUME: return
    try:
        progress_data = {"timestamp": datetime.now().isoformat(), "completed": completed_files, "total": total_files}
        with open(RESUME_LOG_FILE, 'w', encoding='utf-8') as f: json.dump(progress_data, f, ensure_ascii=False, indent=2)
    except Exception as e: print(f"[WARN] ç„¡æ³•å„²å­˜é€²åº¦: {e}")

def load_progress():
    if not ENABLE_RESUME or not os.path.exists(RESUME_LOG_FILE): return None
    try:
        with open(RESUME_LOG_FILE, 'r', encoding='utf-8') as f: return json.load(f)
    except Exception as e:
        print(f"[WARN] ç„¡æ³•è¼‰å…¥é€²åº¦: {e}")
        return None

def timeout_handler():
    global current_processing_file, processing_start_time, force_stop, baseline_completed
    while not force_stop and not baseline_completed:
        time.sleep(10)
        if current_processing_file and processing_start_time:
            elapsed = time.time() - processing_start_time
            if elapsed > FILE_TIMEOUT_SECONDS:
                print(f"\nâ° æª”æ¡ˆè™•ç†è¶…æ™‚! (æª”æ¡ˆ: {current_processing_file}, å·²è™•ç†: {elapsed:.1f}s > {FILE_TIMEOUT_SECONDS}s)")
                current_processing_file = None
                processing_start_time = None

def get_all_excel_files(folders):
    all_files = []
    for folder in folders:
        if os.path.isfile(folder):
            if folder.lower().endswith(SUPPORTED_EXTS) and not os.path.basename(folder).startswith('~$'):
                all_files.append(folder)
        elif os.path.isdir(folder):
            for dirpath, _, filenames in os.walk(folder):
                for f in filenames:
                    if f.lower().endswith(SUPPORTED_EXTS) and not f.startswith('~$'):
                        all_files.append(os.path.join(dirpath, f))
    return all_files

def serialize_cell_value(value):
    if value is None: return None
    if isinstance(value, ArrayFormula): return None
    if isinstance(value, datetime): return value.isoformat()
    if isinstance(value, (int, float, str, bool)): return value
    return str(value)

def get_excel_last_author(path):
    try:
        wb = load_workbook(path, read_only=True)
        author = wb.properties.lastModifiedBy
        wb.close(); del wb
        return author
    except Exception: return None

def copy_to_cache(network_path, silent=False):
    if not USE_LOCAL_CACHE: return network_path
    try:
        os.makedirs(CACHE_FOLDER, exist_ok=True)
        if not os.path.exists(network_path): raise FileNotFoundError(f"ç¶²çµ¡æª”æ¡ˆä¸å­˜åœ¨: {network_path}")
        if not os.access(network_path, os.R_OK): raise PermissionError(f"ç„¡æ³•è®€å–ç¶²çµ¡æª”æ¡ˆ: {network_path}")
        file_hash = hashlib.md5(network_path.encode('utf-8')).hexdigest()[:16]
        cache_file = os.path.join(CACHE_FOLDER, f"{file_hash}_{os.path.basename(network_path)}")
        if os.path.exists(cache_file):
            try:
                if os.path.getmtime(cache_file) >= os.path.getmtime(network_path): return cache_file
            except Exception: pass
        network_size = os.path.getsize(network_path)
        if not silent: print(f"   ğŸ“¥ è¤‡è£½åˆ°ç·©å­˜: {os.path.basename(network_path)} ({network_size/(1024*1024):.1f} MB)")
        copy_start = time.time()
        shutil.copy2(network_path, cache_file)
        if not silent: print(f"      è¤‡è£½å®Œæˆï¼Œè€—æ™‚ {time.time() - copy_start:.1f} ç§’")
        return cache_file
    except Exception as e:
        if not silent: print(f"   âŒ ç·©å­˜å¤±æ•—: {e}")
        return network_path

def dump_excel_cells_with_timeout(path, show_sheet_detail=True, silent=False):
    global current_processing_file, processing_start_time
    current_processing_file = path
    processing_start_time = time.time()
    wb = None
    try:
        if not silent: print(f"   ğŸ“Š æª”æ¡ˆå¤§å°: {os.path.getsize(path)/(1024*1024):.1f} MB")
        local_path = copy_to_cache(path, silent=silent)
        
        read_only_mode = True
        
        if not silent: print(f"   ğŸš€ è®€å–æ¨¡å¼: read_only={read_only_mode}, data_only=False")
        wb = load_workbook(local_path, read_only=read_only_mode, data_only=False)
        result = {}
        worksheet_count = len(wb.worksheets)
        if not silent and show_sheet_detail: print(f"   ğŸ“‹ å·¥ä½œè¡¨æ•¸é‡: {worksheet_count}")
        
        for idx, ws in enumerate(wb.worksheets, 1):
            cell_count = 0
            ws_data = {}
            if ws.max_row > 1 or ws.max_column > 1:
                for row in ws.iter_rows():
                    for cell in row:
                        fstr = get_cell_formula(cell)
                        vstr = serialize_cell_value(cell.value)
                        if fstr is not None or vstr is not None:
                            ws_data[cell.coordinate] = {"formula": fstr, "value": vstr}
                            cell_count += 1
            if show_sheet_detail and not silent: print(f"      è™•ç†å·¥ä½œè¡¨ {idx}/{worksheet_count}: {ws.title}ï¼ˆ{cell_count} æœ‰è³‡æ–™ cellï¼‰")
            if ws_data: result[ws.title] = ws_data
        
        wb.close(); wb = None
        if not silent and show_sheet_detail: print(f"   âœ… Excel è®€å–å®Œæˆ")
        return result
    except Exception as e:
        if not silent: print(f"   âŒ Excel è®€å–å¤±æ•—: {e}")
        return None
    finally:
        if wb: wb.close(); del wb
        current_processing_file = None
        processing_start_time = None

def hash_excel_content(cells_dict):
    if cells_dict is None: return None
    try:
        content_str = json.dumps(cells_dict, sort_keys=True, ensure_ascii=False)
        return hashlib.md5(content_str.encode('utf-8')).hexdigest()
    except Exception: return None

def baseline_file_path(base_name):
    return os.path.join(LOG_FOLDER, f"{base_name}.baseline.json.gz")

def load_baseline(baseline_file):
    try:
        if os.path.exists(baseline_file):
            with gzip.open(baseline_file, 'rt', encoding='utf-8') as f:
                return json.load(f)
        return None
    except Exception as e:
        print(f"[ERROR][load_baseline] {baseline_file}: {e}")
        return None

def save_baseline(baseline_file, data):
    dir_name = os.path.dirname(baseline_file)
    os.makedirs(dir_name, exist_ok=True)
    fd, tmp_path = tempfile.mkstemp(suffix='.tmp', prefix='baseline_', dir=dir_name)
    os.close(fd)
    try:
        with gzip.open(tmp_path, 'wt', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, separators=(',', ':'))
        with gzip.open(tmp_path, 'rt', encoding='utf-8') as f: _ = json.load(f)
        os.replace(tmp_path, baseline_file)
        return True
    except Exception as e:
        print(f"[ERROR][save_baseline] error saving {baseline_file}: {e}")
        if os.path.exists(tmp_path): os.remove(tmp_path)
        return False

def is_force_baseline_file(filepath):
    try:
        for pattern in FORCE_BASELINE_ON_FIRST_SEEN:
            if pattern.lower() in filepath.lower(): return True
        return False
    except Exception: return False

def human_readable_size(num_bytes):
    if num_bytes is None: return "0 B"
    for unit in ['B','KB','MB','GB','TB']:
        if num_bytes < 1024.0: return f"{num_bytes:,.2f} {unit}"
        num_bytes /= 1024.0
    return f"{num_bytes:.2f} PB"

def create_baseline_for_files_robust(xlsx_files, skip_force_baseline=True):
    global force_stop, baseline_completed
    total = len(xlsx_files)
    if total == 0:
        print("[INFO] æ²’æœ‰éœ€è¦ baseline çš„æª”æ¡ˆã€‚")
        baseline_completed = True
        return
    print("\n" + "="*90 + "\n" + " BASELINE å»ºç«‹ç¨‹åº ".center(90, "=") + "\n" + "="*90)
    progress = load_progress()
    start_index = 0
    if progress and ENABLE_RESUME:
        print(f"ğŸ”„ ç™¼ç¾ä¹‹å‰çš„é€²åº¦è¨˜éŒ„: å®Œæˆ {progress.get('completed', 0)}/{progress.get('total', 0)}")
        if input("æ˜¯å¦è¦å¾ä¸Šæ¬¡ä¸­æ–·çš„åœ°æ–¹ç¹¼çºŒ? (y/n): ").strip().lower() == 'y':
            start_index = progress.get('completed', 0)
    if ENABLE_TIMEOUT:
        timeout_thread = threading.Thread(target=timeout_handler, daemon=True); timeout_thread.start()
        print(f"â° å•Ÿç”¨è¶…æ™‚ä¿è­·: {FILE_TIMEOUT_SECONDS} ç§’")
    if ENABLE_MEMORY_MONITOR: print(f"ğŸ’¾ å•Ÿç”¨è¨˜æ†¶é«”ç›£æ§: {MEMORY_LIMIT_MB} MB")
    print(f"ğŸš€ å•Ÿç”¨å„ªåŒ–: {[opt for flag, opt in [(USE_LOCAL_CACHE, 'æœ¬åœ°ç·©å­˜'), (ENABLE_FAST_MODE, 'å¿«é€Ÿæ¨¡å¼')] if flag]}")
    print(f"ğŸ“‚ Baseline å„²å­˜ä½ç½®: {os.path.abspath(LOG_FOLDER)}")
    if USE_LOCAL_CACHE: print(f"ğŸ’¾ æœ¬åœ°ç·©å­˜ä½ç½®: {os.path.abspath(CACHE_FOLDER)}")
    print(f"ğŸ“‹ è¦è™•ç†çš„æª”æ¡ˆ: {total} å€‹ (å¾ç¬¬ {start_index + 1} å€‹é–‹å§‹)")
    print(f"â° é–‹å§‹æ™‚é–“: {datetime.now():%Y-%m-%d %H:%M:%S}\n" + "-"*90)
    os.makedirs(LOG_FOLDER, exist_ok=True)
    if USE_LOCAL_CACHE: os.makedirs(CACHE_FOLDER, exist_ok=True)
    
    success_count, skip_count, error_count = 0, 0, 0
    start_time = time.time()
    for i in range(start_index, total):
        if force_stop:
            print("\nğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡è™Ÿï¼Œæ­£åœ¨å®‰å…¨é€€å‡º..."); save_progress(i, total); break
        
        file_path = xlsx_files[i]
        base_name = os.path.basename(file_path)
        
        if check_memory_limit():
            print(f"âš ï¸ è¨˜æ†¶é«”ä½¿ç”¨é‡éé«˜ï¼Œæš«åœ10ç§’..."); time.sleep(10)
            if check_memory_limit(): print(f"âŒ è¨˜æ†¶é«”ä»ç„¶éé«˜ï¼Œåœæ­¢è™•ç†"); save_progress(i, total); break

        file_start_time = time.time()
        print(f"[{i+1:>2}/{total}] è™•ç†ä¸­: {base_name} (è¨˜æ†¶é«”: {get_memory_usage():.1f}MB)")
        cell_data = None
        try:
            baseline_file = baseline_file_path(base_name)
            old_baseline = load_baseline(baseline_file)
            old_hash = old_baseline['content_hash'] if old_baseline and 'content_hash' in old_baseline else None
            
            cell_data = dump_excel_cells_with_timeout(file_path)
            
            if cell_data is None:
                if current_processing_file is None and (time.time() - file_start_time) > FILE_TIMEOUT_SECONDS:
                     print(f"  çµæœ: [TIMEOUT]")
                else:
                     print(f"  çµæœ: [READ_ERROR]")
                error_count += 1
            else:
                curr_hash = hash_excel_content(cell_data)
                if old_hash == curr_hash and old_hash is not None:
                    print(f"  çµæœ: [SKIP] (Hash unchanged)"); skip_count += 1
                else:
                    curr_author = get_excel_last_author(file_path)
                    if save_baseline(baseline_file, {"last_author": curr_author, "content_hash": curr_hash, "cells": cell_data}):
                        print(f"  çµæœ: [OK]")
                        # PATCH: Add back the baseline creation confirmation message
                        print(f"  Baseline: {os.path.basename(baseline_file)}")
                        success_count += 1
                    else:
                        print(f"  çµæœ: [SAVE_ERROR]"); error_count += 1
            
            print(f"  è€—æ™‚: {time.time() - file_start_time:.2f} ç§’\n")
            save_progress(i + 1, total)
        except Exception as e:
            print(f"  çµæœ: [UNEXPECTED_ERROR]\n  éŒ¯èª¤: {e}\n  è€—æ™‚: {time.time() - file_start_time:.2f} ç§’\n"); error_count += 1
            save_progress(i + 1, total)
        finally:
            if cell_data is not None: del cell_data
            if 'old_baseline' in locals() and old_baseline is not None: del old_baseline
            gc.collect()

    baseline_completed = True
    print("-" * 90 + f"\nğŸ¯ BASELINE å»ºç«‹å®Œæˆ! (ç¸½è€—æ™‚: {time.time() - start_time:.2f} ç§’)")
    print(f"âœ… æˆåŠŸ: {success_count}, â­ï¸  è·³é: {skip_count}, âŒ å¤±æ•—: {error_count}")
    if ENABLE_RESUME and os.path.exists(RESUME_LOG_FILE):
        try: os.remove(RESUME_LOG_FILE); print(f"ğŸ§¹ æ¸…ç†é€²åº¦æª”æ¡ˆ")
        except Exception: pass
    print("\n" + "=" * 90 + "\n")

def compare_excel_changes(file_path, silent=True, event_number=None, is_polling=False):
    old_baseline, curr_cells, changes = None, None, None
    has_changes = False
    try:
        base_name = os.path.basename(file_path)
        baseline_file = baseline_file_path(base_name)
        old_baseline = load_baseline(baseline_file)
        
        if not old_baseline:
            if not silent: print(f"[INFO] æ²’æœ‰ baseline: {base_name}ï¼Œå»ºç«‹æ–° baseline...")
            cell_data = dump_excel_cells_with_timeout(file_path, show_sheet_detail=True, silent=silent)
            if cell_data is None: return False
            curr_author = get_excel_last_author(file_path)
            curr_hash = hash_excel_content(cell_data)
            if save_baseline(baseline_file, {"last_author": curr_author, "content_hash": curr_hash, "cells": cell_data}):
                print(f"  Baseline: {os.path.basename(baseline_file)}")
            del cell_data
            return True

        curr_cells = dump_excel_cells_with_timeout(file_path, show_sheet_detail=False, silent=silent)
        
        if curr_cells is None:
            print(f"[ERROR] è®€å–æª”æ¡ˆå¤±æ•—ï¼Œç„¡æ³•æ¯”è¼ƒ: {base_name}")
            return False
            
        curr_hash = hash_excel_content(curr_cells)
        old_hash = old_baseline.get('content_hash')
        
        if curr_hash == old_hash:
            if not silent and not is_polling: print(f"[INFO] æª”æ¡ˆç„¡è®Šæ›´: {base_name}")
            return False
            
        has_changes = True
        curr_author = get_excel_last_author(file_path)
        
        if event_number is not None and not is_polling:
            print("\n" + "="*50 + f"\nğŸŸ¢ [äº‹ä»¶ #{event_number}] {datetime.now():%Y-%m-%d %H:%M:%S}")
        
        print(f"ğŸš¨ [æª”æ¡ˆæœ‰è®Šæ›´] {base_name}")
        print(f"  ä½œè€…: {old_baseline.get('last_author', 'N/A')} â†’ {curr_author or 'N/A'}")
        
        old_h_str = f"{old_hash[:8]}..." if old_hash else "N/A"
        new_h_str = f"{curr_hash[:8]}..." if curr_hash else "N/A"
        print(f"  Hash: {old_h_str} â†’ {new_h_str}")
        
        changes = []
        old_cells = old_baseline.get('cells', {})
        all_ws_names = set(old_cells.keys()) | set(curr_cells.keys())
        for ws_name in all_ws_names:
            old_ws_cells, curr_ws_cells = old_cells.get(ws_name, {}), curr_cells.get(ws_name, {})
            all_coords = set(old_ws_cells.keys()) | set(curr_ws_cells.keys())
            for cell_coord in all_coords:
                old_cell = old_ws_cells.get(cell_coord, {"formula": None, "value": None})
                curr_cell = curr_ws_cells.get(cell_coord, {"formula": None, "value": None})
                if old_cell['formula'] != curr_cell['formula'] or str(old_cell['value']) != str(curr_cell['value']):
                    changes.append({'worksheet': ws_name, 'cell': cell_coord,
                                    'old_formula': old_cell['formula'], 'old_value': old_cell['value'],
                                    'new_formula': curr_cell['formula'], 'new_value': curr_cell['value']})

        ref_map = extract_external_refs(file_path)
        filtered_changes = [enrich_formula_external_path(c, ref_map) for c in changes if not should_filter_change(c, FORMULA_ONLY_MODE)]
        
        if not filtered_changes:
            if not is_polling: print("  [INFO] å…§å®¹æœ‰è®Šæ›´ï¼Œä½†éæ¿¾å¾Œç„¡é¡¯è‘—å·®ç•°ã€‚")
            save_baseline(baseline_file, {"last_author": curr_author, "content_hash": curr_hash, "cells": curr_cells})
            return True

        print_cell_changes_summary(filtered_changes)
        log_changes_to_csv(file_path, curr_author, filtered_changes)
        save_baseline(baseline_file, {"last_author": curr_author, "content_hash": curr_hash, "cells": curr_cells})
        return True
    except Exception as e:
        print(f"[ERROR] æ¯”è¼ƒæª”æ¡ˆå¤±æ•—: {file_path} - {e}")
        import traceback; traceback.print_exc()
        return False
    finally:
        if old_baseline: del old_baseline
        if curr_cells: del curr_cells
        if changes: del changes
        gc.collect()

def print_cell_changes_summary(changes, max_show=10):
    try:
        print(f"  è®Šæ›´ cell æ•¸é‡ï¼š{len(changes)}")
        maxlen = 50
        for i, change in enumerate(changes[:max_show]):
            ws, cell = change['worksheet'], change['cell']
            old_f, old_v = change['old_formula'] or "", str(change['old_value'] or "")
            new_f, new_v = change['new_formula'] or "", str(change['new_value'] or "")
            print(f"    [{ws}] {cell}:")
            if old_f != new_f:
                # åŠ å…¥é™¤éŒ¯ä¿¡æ¯
                old_f_type = type(change['old_formula']).__name__ if change['old_formula'] else "None"
                new_f_type = type(change['new_formula']).__name__ if change['new_formula'] else "None"
                
                old_f_str, new_f_str = str(old_f), str(new_f)
                if len(old_f_str) > maxlen or len(new_f_str) > maxlen:
                    print(f"        [å…¬å¼] '{old_f_str}' ({old_f_type})")
                    print(f"              -> '{new_f_str}' ({new_f_type})")
                else: 
                    print(f"        [å…¬å¼] '{old_f_str}' ({old_f_type}) -> '{new_f_str}' ({new_f_type})")
            if str(old_v) != str(new_v):
                old_v_str, new_v_str = str(old_v), str(new_v)
                if len(old_v_str) > maxlen or len(new_v_str) > maxlen:
                    print(f"        [å€¼]   '{old_v_str}'")
                    print(f"              -> '{new_v_str}'")
                else: 
                    print(f"        [å€¼]   '{old_v_str}' -> '{new_v_str}'")
        if len(changes) > max_show: 
            print(f"    ... å…¶é¤˜ {len(changes) - max_show} å€‹ cell çœç•¥ ...")
    except Exception as e: 
        print(f"[ERROR][print_cell_changes_summary] {e}")

def log_changes_to_csv(file_path, author, changes):
    try:
        os.makedirs(LOG_FOLDER, exist_ok=True)
        is_new_file = not os.path.exists(CSV_LOG_FILE)
        with gzip.open(CSV_LOG_FILE, 'at', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            if is_new_file: writer.writerow(['Timestamp', 'File Path', 'Author', 'Worksheet', 'Cell', 'Old Formula', 'Old Value', 'New Formula', 'New Value'])
            for change in changes:
                writer.writerow([f"{datetime.now():%Y-%m-%d %H:%M:%S}", file_path, author, change['worksheet'], change['cell'], 
                                 change['old_formula'], change['old_value'], change['new_formula'], change['new_value']])
    except Exception as e:
        print(f"[ERROR] è¨˜éŒ„ CSV å¤±æ•—: {e}")

event_counter = 1
event_counter_lock = threading.Lock()

class ExcelChangeHandler(FileSystemEventHandler):
    def __init__(self):
        self.processing_files = set()
        self.lock = threading.Lock()

    def on_modified(self, event):
        global event_counter
        if event.is_directory or not event.src_path.lower().endswith(SUPPORTED_EXTS) or os.path.basename(event.src_path).startswith('~$'):
            return
        
        file_path = event.src_path
        
        with self.lock:
            if file_path in self.processing_files: return
            self.processing_files.add(file_path)

        current_event_num = None
        with event_counter_lock:
            current_event_num = event_counter
        
        has_changes = compare_excel_changes(file_path, silent=False, event_number=current_event_num)
        
        if has_changes:
            with event_counter_lock:
                event_counter += 1
            active_polling_handler.start_polling(file_path, current_event_num)
        
        with self.lock:
            if file_path in self.processing_files:
                self.processing_files.remove(file_path)

def start_watchdog_monitor():
    global force_stop
    force_stop = False
    print("\n" + "="*80 + "\n" + " å•Ÿå‹• Excel æª”æ¡ˆç›£æ§ ".center(80, "=") + "\n" + "="*80)
    valid_folders = [folder for folder in WATCH_FOLDERS if os.path.exists(folder)]
    if not valid_folders:
        print("âŒ æ²’æœ‰æœ‰æ•ˆçš„ç›£æ§è³‡æ–™å¤¾ï¼Œç„¡æ³•å•Ÿå‹•ç›£æ§"); return
    print("  ç›£æ§è³‡æ–™å¤¾:")
    for folder in valid_folders: print(f"    ğŸ“‚ {folder}")
    print(f"\n  æ”¯æ´æª”æ¡ˆ: {SUPPORTED_EXTS}\n  è®Šæ›´è¨˜éŒ„: {CSV_LOG_FILE}")
    
    event_handler = ExcelChangeHandler()
    observer = Observer()
    for folder in valid_folders:
        observer.schedule(event_handler, folder, recursive=True)
    
    print("\nğŸ” ç›£æ§ä¸­... (æŒ‰ Ctrl+C åœæ­¢)\n" + "-"*80)
    observer.start()
    try:
        while not force_stop: time.sleep(1)
    except KeyboardInterrupt:
        print("\nğŸ›‘ æ”¶åˆ° Ctrl+C åœæ­¢ä¿¡è™Ÿ...")
    finally:
        active_polling_handler.stop()
        observer.stop()
        observer.join()
        print("ğŸ“„ ç›£æ§å·²åœæ­¢")

def print_console_header():
    print("\n" + "="*80 + "\n" + " Excel File Change Watcher (è¨ºæ–·å¼·åŒ–ç‰ˆæœ¬) ".center(80, "-") + "\n" + "="*80)
    print(f"  ç›®å‰ä½¿ç”¨è€…: {os.getlogin()}")

if __name__ == "__main__":
    try:
        print_console_header()
        os.makedirs(LOG_FOLDER, exist_ok=True)
        if USE_LOCAL_CACHE: os.makedirs(CACHE_FOLDER, exist_ok=True)
        
        if SCAN_ALL_MODE:
            all_files = get_all_excel_files(WATCH_FOLDERS)
            print(f"ç¸½å…±æ‰¾åˆ° {len(all_files)} å€‹ Excel æª”æ¡ˆã€‚")
            create_baseline_for_files_robust(all_files, skip_force_baseline=True)
        else:
            target_files = get_all_excel_files(MANUAL_BASELINE_TARGET)
            print(f"æ‰‹å‹•æŒ‡å®š baselineï¼Œåˆå…± {len(target_files)} å€‹ Excel æª”æ¡ˆã€‚")
            create_baseline_for_files_robust(target_files, skip_force_baseline=False)
        
        if force_stop:
            print("ğŸ›‘ ç¨‹åºåœ¨ baseline éšæ®µè¢«ä¸­æ–·ï¼Œé€€å‡º...")
        else:
            start_watchdog_monitor()
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç¨‹åºè¢«ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"\n[CRITICAL ERROR][main] ç¨‹å¼ä¸»æµç¨‹ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}")
        import traceback; traceback.print_exc()
    finally:
        print("\nç¨‹åºçµæŸã€‚")
